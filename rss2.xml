<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>KasterMist</title>
    <link>http://example.com/</link>
    
    <atom:link href="http://example.com/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>胸有惊雷，面如平湖</description>
    <pubDate>Wed, 13 Mar 2024 11:57:38 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>CUDA学习(十)--书籍中的函数整合</title>
      <link>http://example.com/2024/03/11/CUDA%E5%AD%A6%E4%B9%A0-%E5%8D%81-%E4%B9%A6%E7%B1%8D%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E6%95%B4%E5%90%88/</link>
      <guid>http://example.com/2024/03/11/CUDA%E5%AD%A6%E4%B9%A0-%E5%8D%81-%E4%B9%A6%E7%B1%8D%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E6%95%B4%E5%90%88/</guid>
      <pubDate>Mon, 11 Mar 2024 01:05:40 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;前面几章主要是对参考书目的内容进行一个概括。本章将根据参考书目的内容对所学到的所有函数进行一个整理和总结，以便复习和参考。英伟达的官方网站包含了所有的CUDA函数，可参考&lt;a href=&quot;https://developer.download.nvidia.cn/comput</description>
        
      
      
      
      <content:encoded><![CDATA[<p>前面几章主要是对参考书目的内容进行一个概括。本章将根据参考书目的内容对所学到的所有函数进行一个整理和总结，以便复习和参考。英伟达的官方网站包含了所有的CUDA函数，可参考<a href="https://developer.download.nvidia.cn/compute/DevZone/docs/html/C/doc/html/index.html%E3%80%82">https://developer.download.nvidia.cn/compute/DevZone/docs/html/C/doc/html/index.html。</a></p><h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><p>这部分将介绍一下CUDA的基本语法，即参数的创建、传递、释放。</p><h4 id="cudaMalloc"><a href="#cudaMalloc" class="headerlink" title="cudaMalloc"></a>cudaMalloc</h4><p>cudaMalloc函数的语法结构如下表示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaMalloc</span><span class="params">(<span class="type">void</span>** devPtr, <span class="type">size_t</span> size)</span></span><br></pre></td></tr></table></figure><p>与C的malloc相似，cudaMalloc在设备上分配“size”字节大小的线性内存，并在*devPtr中返回一个指向所分配内存的指针。所分配的内存对于任何类型的变量都是适当对齐的。如果分配成功，则返回<code>cudaSuccess</code>，如果分配失败，则会返回<code>cudaErrorMemoryAllocation</code>。</p><p>注意，void** devPtr表示需要传递指针的地址。</p><h4 id="cudaMemcpy"><a href="#cudaMemcpy" class="headerlink" title="cudaMemcpy"></a>cudaMemcpy</h4><p>cudaMemcpy函数的语法如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaMemcpy</span><span class="params">(<span class="type">void</span>* dst, <span class="type">const</span> <span class="type">void</span>* src, <span class="type">size_t</span>, count, <span class="keyword">enum</span> cudaMemcpyKind kind)</span></span><br></pre></td></tr></table></figure><p>将“count”字节从src指向的内存区域复制到dst指向的内存区。</p><p>dst是目标位置destination，src是源位置source。</p><p>kind用于规定复制的方向，总共有以下几种：</p><ul><li>cudaMemcpyHostToHost</li><li>cudaMemcpyHostToDevice</li><li>cudaMemcpyDeviceToHost</li><li>cudaMemcpyDeviceToDevice</li></ul><p>返回的值有：</p><ul><li>cudaSuccess</li><li>cudaErrorInvalidValue</li><li>cudaErrorInvalidDevicePointer</li><li>cudaErrorInvalidMemcpyDirection</li></ul><p>注：此函数还可能返回以前异步启动的错误代码。</p><h4 id="cudaFree"><a href="#cudaFree" class="headerlink" title="cudaFree"></a>cudaFree</h4><p>cudaFree函数的语法如下所示</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaFree</span><span class="params">(<span class="type">void</span>* devPtr)</span></span><br></pre></td></tr></table></figure><p>释放devPtr指向的内存。与cudaMalloc()或者cudaMallocPitch()一一对应，对之前分配的内存进行释放。</p><p>返回的值有：</p><ul><li>cudaSuccess</li><li>cudaErrorInvalidDevicePointer</li><li>cudaErrorInitializationError</li></ul><p>注：此函数还可能返回以前异步启动的错误代码。</p><h4 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h4><p>核函数前面需要加上__global__，此方法会将函数标记为设备代码“Device Code”。函数格式可以为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="title function_">kernel</span><span class="params">(arguments)</span></span><br></pre></td></tr></table></figure><p>进行函数调用的格式可以为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(arguments)</span><br></pre></td></tr></table></figure><p>下面将详细介绍threads，blocks相关概念。也可以参考以下链接：<a href="https://zhuanlan.zhihu.com/p/675603584">https://zhuanlan.zhihu.com/p/675603584</a></p><p>CUDA里面用Grid和Block作为线程组织的组织单位，一个Grid可包含了N个Block，一个Block包含N个thread。</p><p>我们一般用得到的参数是gridDim, blockDim, blockIdx和threadIdx。</p><ul><li>gridDim: dim3类型，表示blocks在grid里面数量的维度。</li><li>blockDim：dim3类型，表示threads在block里面数量的维度。</li><li>blockIdx：dim3类型，表示blocks在grid里面的索引。</li><li>threadIdx：dim3类型，表示threads在block里面的索引。</li></ul><p><img src="/imgs/CUDA_10_1.png" alt="CUDA_10_1"></p><p>上图给了一个参考的thread和block的结构。在上面的结构中，一个grid有2*3个block块，每个block块各有15*15个thread。x轴是从左往右，y轴是从上到下(示例图片并没有显示z轴，即z轴最大值为1)。</p><p>如何获取某个thread的坐标，可以分为以下几步：</p><ol><li><p>计算thread在block中的位置<br>$$<br>threadInBlock &#x3D; threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * blockDim.x * blockDim.y<br>$$</p></li><li><p>计算该block在grid中的位置<br>$$<br>blockInGrid &#x3D; blockIdx.x + blockIdx.y * gridDim.x + blockIdx.z * gridDim.x * gridDim.y<br>$$</p></li><li><p>计算每个block的线程，计算得出某个thread的位置索引<br>$$<br>oneBlockSize &#x3D; blockDim.x * blockDim.y * blockDim.z<br>$$</p></li></ol><p>$$<br>idx &#x3D; threadInBlock + oneBlockSize * blockInGrid<br>$$</p><h2 id="查询设备"><a href="#查询设备" class="headerlink" title="查询设备"></a>查询设备</h2><h4 id="cudaGetDevice"><a href="#cudaGetDevice" class="headerlink" title="cudaGetDevice"></a>cudaGetDevice</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaGetDevice</span><span class="params">(<span class="type">int</span>* device)</span></span><br></pre></td></tr></table></figure><p>将当前主机线程调用的设备索引返回给device的地址。</p><h4 id="cudaGetDeviceCount"><a href="#cudaGetDeviceCount" class="headerlink" title="cudaGetDeviceCount"></a>cudaGetDeviceCount</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaGetDeviceCount</span><span class="params">(<span class="type">int</span>* count)</span></span><br></pre></td></tr></table></figure><p>返回可执行的设备数量到count的地址。如果没有这样的设备，则返回cudaErrorNoDevice。如果无法加载驱动程序来确定是否存在任何此类设备，则返回cudaErrorInsufficientDriver。</p><h4 id="cudaGetDeviceProperties"><a href="#cudaGetDeviceProperties" class="headerlink" title="cudaGetDeviceProperties"></a>cudaGetDeviceProperties</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaGetDeviceProperties</span><span class="params">(<span class="keyword">struct</span> cudaDeviceProp* prop, <span class="type">int</span> device)</span></span><br></pre></td></tr></table></figure><p>将device的属性的信息传递给prop。cudaDeviceProp结构可以参考下面的链接：</p><p><a href="https://developer.download.nvidia.cn/compute/DevZone/docs/html/C/doc/html/group__CUDART__DEVICE_g5aa4f47938af8276f08074d09b7d520c.html#g5aa4f47938af8276f08074d09b7d520c">https://developer.download.nvidia.cn/compute/DevZone/docs/html/C/doc/html/group__CUDART__DEVICE_g5aa4f47938af8276f08074d09b7d520c.html#g5aa4f47938af8276f08074d09b7d520c</a></p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><h4 id="共享内存-Shared-Memory"><a href="#共享内存-Shared-Memory" class="headerlink" title="共享内存(Shared Memory)"></a>共享内存(Shared Memory)</h4><ul><li>共享内存是在GPU的<strong>每个线程块（block）中</strong>共享的内存空间，用于线程之间的通信和数据共享。</li><li>共享内存的访问速度比全局内存更快，因为它位于芯片上，与处理器更近。</li><li>共享内存的使用需要程序员显式地将数据从全局内存复制到共享内存中，并在使用完毕后将数据写回全局内存。</li><li>共享内存在内核中的声明是在内核函数的参数列表之外使用 <code>__shared__</code> 关键字。</li></ul><h4 id="全局内存-Global-Memory"><a href="#全局内存-Global-Memory" class="headerlink" title="全局内存(Global Memory)"></a>全局内存(Global Memory)</h4><ul><li>全局内存是GPU中<strong>所有线程</strong>都可以访问的主要内存池，在设备内存中分配。</li><li>全局内存的访问速度相对较慢，因为它位于芯片之外，需要通过总线等方式与GPU核心通信。</li><li>全局内存通常用于存储大规模的数据，如数组、结构体等。</li><li>全局内存可以通过 <code>cudaMalloc</code> 分配内存，并使用 <code>cudaMemcpy</code> 在主机内存和设备内存之间进行数据传输。</li></ul><h4 id="常量内存-Constant-Memory"><a href="#常量内存-Constant-Memory" class="headerlink" title="常量内存(Constant Memory)"></a>常量内存(Constant Memory)</h4><ul><li><p>常量内存是GPU上的一种只读内存，用于存储在GPU核心中被<strong>所有线程共享的常量数据</strong>。</p></li><li><p>常量内存通常用于存储对所有线程都是常量的数据，比如常量数组、常量参数等。</p></li><li><p>常量内存的优势在于其高速缓存和对齐的特性，可以加速访问频繁的常量数据。</p></li><li><p>常量内存的访问速度比全局内存更快，但相对来说容量较小。</p></li><li><p>常量内存通常在内核启动之前被初始化，并且其内容在内核执行期间不会改变。可以使用 CUDA 的 <code>__constant__</code> 修饰符定义常量内存，使用 <code>cudaMemcpyToSymbol</code> 将数据从主机内存拷贝到常量内存中。</p></li></ul><p>以下是GPT生成的一个常量内存的使用例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义常量数组大小</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ARRAY_SIZE 10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 声明常量内存</span></span><br><span class="line">__constant__ <span class="type">int</span> constantArray[ARRAY_SIZE];</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核函数</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">kernel</span><span class="params">(<span class="type">int</span> *result)</span> &#123;</span><br><span class="line">    <span class="comment">// 获取线程索引</span></span><br><span class="line">    <span class="type">int</span> idx = threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用常量内存中的数据进行计算</span></span><br><span class="line">    result[idx] = constantArray[idx] * idx;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> hostArray[ARRAY_SIZE];</span><br><span class="line">    <span class="type">int</span> *devResult;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化常量数组</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; ARRAY_SIZE; ++i) &#123;</span><br><span class="line">        hostArray[i] = i + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分配设备端内存</span></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;devResult, ARRAY_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将常量数组拷贝到设备端常量内存中</span></span><br><span class="line">    cudaMemcpyToSymbol(constantArray, hostArray, ARRAY_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 调用内核函数</span></span><br><span class="line">    kernel&lt;&lt;&lt;<span class="number">1</span>, ARRAY_SIZE&gt;&gt;&gt;(devResult);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 同步CUDA流，确保内核执行完成</span></span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果拷贝回主机端</span></span><br><span class="line">    <span class="type">int</span> result[ARRAY_SIZE];</span><br><span class="line">    cudaMemcpy(result, devResult, ARRAY_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印结果</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Result:\n&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; ARRAY_SIZE; ++i) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, result[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放设备端内存</span></span><br><span class="line">    cudaFree(devResult);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><h2 id="线程同步"><a href="#线程同步" class="headerlink" title="线程同步"></a>线程同步</h2><h4 id="syncthreads"><a href="#syncthreads" class="headerlink" title="__syncthreads"></a>__syncthreads</h4><p><code>__syncthreads()</code>函数的功能是<strong>确保同一个线程块的线程</strong>执行完该语句之前的所有语句。使用<code>__syncthreads()</code>需要注意的点是要确保所有线程都能够执行该语句，否则其他线程就会永远等待那些执行不了该语句的线程，从而停止下一步的执行。</p><p>注：CUDA并没有提供一个可以同步所有线程（包括不同线程块）的函数。这是因为CUDA的并行模型设计使得在不同线程块之间进行同步更加困难和昂贵。通常情况下，CUDA编程模型假设各个线程块是独立执行的，并且不会直接相互影响。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/03/11/CUDA%E5%AD%A6%E4%B9%A0-%E5%8D%81-%E4%B9%A6%E7%B1%8D%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E6%95%B4%E5%90%88/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(九)</title>
      <link>http://example.com/2024/03/09/CUDA%E5%AD%A6%E4%B9%A0-%E4%B9%9D/</link>
      <guid>http://example.com/2024/03/09/CUDA%E5%AD%A6%E4%B9%A0-%E4%B9%9D/</guid>
      <pubDate>Sat, 09 Mar 2024 13:27:36 GMT</pubDate>
      
      <description>&lt;p&gt;这部分是基于原子操作章节进行的高级操作介绍，即实现锁定数据结构。&lt;/p&gt;
&lt;p&gt;原子操作只能确保每个线程在完成读取-修改-写入的序列之前，将不会有其他的线程读取或者写入目标内存。然而，原子操作并不能确保这些线程将按照何种顺序执行。例如当有三个线程都执行加法运算时，加法运行的执行顺序可以为(A + B) + C，也可以为A + (B + C)。这对于整数来说是可以接受的，因为中间结果可能被截断，因此(A + B) + C通常并不等于A + (B + c)。因此，浮点数值上的原子数学运算是否有用就值得怀疑🤔。因此在早期的硬件中，浮点数学运算并不是优先支持的功能。&lt;/p&gt;
&lt;p&gt;然而，如果可以容忍在计算结果中存在某种程度的不确定性，那么仍然可以完全在GPU上实现归约运算。我们首先需要通过某种方式来绕开原子浮点数学运算。在这个解决方案中仍将使用原子操作，但不是用于算数本身。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>这部分是基于原子操作章节进行的高级操作介绍，即实现锁定数据结构。</p><p>原子操作只能确保每个线程在完成读取-修改-写入的序列之前，将不会有其他的线程读取或者写入目标内存。然而，原子操作并不能确保这些线程将按照何种顺序执行。例如当有三个线程都执行加法运算时，加法运行的执行顺序可以为(A + B) + C，也可以为A + (B + C)。这对于整数来说是可以接受的，因为中间结果可能被截断，因此(A + B) + C通常并不等于A + (B + c)。因此，浮点数值上的原子数学运算是否有用就值得怀疑🤔。因此在早期的硬件中，浮点数学运算并不是优先支持的功能。</p><p>然而，如果可以容忍在计算结果中存在某种程度的不确定性，那么仍然可以完全在GPU上实现归约运算。我们首先需要通过某种方式来绕开原子浮点数学运算。在这个解决方案中仍将使用原子操作，但不是用于算数本身。</p><span id="more"></span><h3 id="原子锁"><a href="#原子锁" class="headerlink" title="原子锁"></a>原子锁</h3><p>基本思想是，分配一小块内存作为互斥体，互斥体这个资源可以是一个数据结构，一个缓冲区，或者是一个需要以原子方式修改的内存位置。当某个线程从这个互斥体中读到0时，表示没有其他线程使用这块内存。因此，该线程就可以锁定这块内存，并执行想要的修改，而不会收到其他线程的干扰。要锁定这个内存位置，线程将1写入互斥体，这将防止其他竞争的线程锁定这个内存。然后，其他竞争线程必须等待直到互斥体的所有线程将0写入到互斥体后才能尝试修改被锁定的内存。实现锁定过程的代码可以像下面这样:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(*mutex == <span class="number">0</span>)&#123;</span><br><span class="line">        *mutex = <span class="number">1</span>; <span class="comment">//将1保存到锁</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不过这段代码中存在一个严重的问题。如果在线程读取到0并且还没有修改这个值之前，另一个线程将1写入到互斥体，那么会发生什么情况？也就是说，这两个线程都将检查mutex上的值，并判断其是否为0。然后，它们都将1写入到这个位置，并且都执行后面的语句。这会产生严重的后果。</p><p>我们想要完成的操作是：将mutex的值与0相比较，如果mutex等于0，则将1写入到这个位置。要正确实现这个操作，整个运算都需要以原子方式执行，这样就可以确保当线程当线程检查和更新mutex值时，不会有其他的线程进行干扰。在CUDA中，这个操作可以通过函数atomicCAS()来实现，这是一个原子的比较-交换操作(Compare-and-Swap)。函数atomicCAS()的参数包括一个指向目标内存的指针，一个与内存中的值进行比较的值，以及一个当比较相等时保存到目标内存上的值。通过这个操作，我们可以实现一个GPU锁定函数，如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__device__ <span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(atomicCAS(mutex, <span class="number">0</span>, <span class="number">1</span>) != <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用atomicCAS()将返回位于mutex地址上的值。<strong>因此while循环会不断运行，直到atomicCAS发现mutex的值为0。当发现为0时，比较操作成功，线程将把1写入到mutex。本质上来看，这个线程将在while循环中不断重复，直到它成功地锁定这个数据结构。</strong>我们将使用这个锁定机制来实现GPU散列表。下面是一种实现方式：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Lock</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> *mutex;</span><br><span class="line">    Lock(<span class="type">void</span>)&#123;</span><br><span class="line">        <span class="type">int</span> state = <span class="number">0</span>;</span><br><span class="line">        HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp; mutex, <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">        HANDLE_ERROR(cudaMemcpy(mutex, &amp;state, <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ~Lock(<span class="type">void</span>)&#123;</span><br><span class="line">        cudaFree(mutex);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    __device__ <span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(atomicCAS(mutex, <span class="number">0</span>, <span class="number">1</span>) != <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    __device <span class="type">void</span> <span class="title function_">unlock</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">        atomicExch(mutex, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码中通过atomicExch(mutex, 0)来重制mutex的值，将其与第二个参数进行交换，并返回它读到的值。然而，为什么不用跟简单的方法，例如<code>*mutex = 0;</code>呢，因为原子事务和常规的内存操作将采用不同的执行路径。如果同时使用原子操作和标准的全局内存操作，那么将使得unlock()与后面的lock()调用看上去似乎没有被同步。虽然这种混合使用的方式仍可以实现正确的功能，但是为了增加应用程序的可读性，对于所有对互斥体的访问都应使用相同的方式。因此，在使用原子语句来锁定资源后，同样应使用原子语句来解锁资源。</p><p>我们想要在最早的点积运算示例中加上原子锁。Lock结构位于lock.h中，在修改后的点积示例中将包含这个头文件。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/book.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;lock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> imin(a, b) (a &lt; b ? a : b)</span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">33</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> blocksPerGrid = imin(<span class="number">32</span>, (N + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock);</span><br></pre></td></tr></table></figure><p>核函数也有所不同，在修改后的点积函数中，将Lock类型的变量，以及输入矢量和输出缓冲区传递给核函数。Lock将被用于在最后的累加步骤中控制对输出缓冲区的访问。另一处修改是float *c。之前float *c是一个包含N个浮点数的缓冲区，其中每个线程块都将其计算得到的临时结果保存到相应的元素中。这个缓冲区将被复制到CPU以便计算最终的点积值。然而，现在的参数c将不再指向一个缓冲区，而是指向一个浮点数值，这个值表示a和b中矢量的点积。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">dot</span><span class="params">(Lock lock, <span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">float</span> *c)</span>&#123;</span><br><span class="line">    __shared__ <span class="type">float</span> cache[threadsPerBlock];</span><br><span class="line">    <span class="type">int</span> tid = threadIds.s + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> cacheIndex = threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> temp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(tid &lt; N)&#123;</span><br><span class="line">        temp += a[tid] * b[tid];</span><br><span class="line">        tid += blockDim.x * gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//设置cache中相应位置上的值</span></span><br><span class="line">    cache[cacheIndex] = temp;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//对线程块中的线程进行同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//对于归约运算来说，以下代码要求threadPerBlock必须是2的幂</span></span><br><span class="line">    <span class="type">int</span> i = blockDim.x / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span>(i != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(cacheIndex &lt; i)&#123;</span><br><span class="line">            cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        i /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br></pre></td></tr></table></figure><p>现在到执行到这里时，每个线程块中的256个线程都已经把各自计算的乘积相加起来，并且保存到cache[0]中。现在，每个线程块都需要将其临时结果相加到c执行的内存位置上。为了安全地执行这个操作，我们将使用锁来控制对该内存位置的访问，因此每个线程在更新*c的值之前，要先获取这个锁。在线程块的临时结果与c处的值相加后，将解锁互斥体，这样其他的线程可以继续累加它们的值。在将临时值与最终结果相加后，这个线程块将不再需要任何计算，因此从核函数中返回。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">if</span>(cacheIndex == <span class="number">0</span>)&#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        *c += cache[<span class="number">0</span>];</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是main函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">float</span> *a, *b, c = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> *dev_a, *dev_b, *dev_c;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在CPU上分配内存</span></span><br><span class="line">    a = (<span class="type">float</span>*)<span class="built_in">malloc</span>(N * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    b = (<span class="type">float</span>*)<span class="built_in">malloc</span>(N * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a, N * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_b, N * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_c, N * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//用数据填充主机内存</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = i * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将数组“a“和”b“复制到GPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_a, a, N * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_b, b, N * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    <span class="comment">//将“0”复制到dev_c</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_c, &amp;c, N * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//声明Lock，调用核函数，并将结果复制回CPU。</span></span><br><span class="line">    Lock lock;</span><br><span class="line">    dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(lock, dev_a, dev_b, dev_c);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将数组“c”从GPU复制到CPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(&amp;c, dev_a, <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDeviceToHost));</span><br><span class="line">    </span><br><span class="line">    <span class="meta">#<span class="keyword">define</span> sum_squares(x) (x * (x + 1) * (2 * x + 1) / 6)</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Does GPU value %.6g = %.6g?\n&quot;</span>, c, <span class="number">2</span> * sum_squares((<span class="type">float</span>)(N - <span class="number">1</span>)));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//释放GPU上的内存</span></span><br><span class="line">    cudaFree(dev_a);</span><br><span class="line">    cudaFree(dev_b);</span><br><span class="line">    cudaFree(dev_c);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//释放CPU上的内存</span></span><br><span class="line">    <span class="built_in">free</span>(a);</span><br><span class="line">    <span class="built_in">free</span>(b);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="散列表-Hash-Table"><a href="#散列表-Hash-Table" class="headerlink" title="散列表 (Hash Table)"></a>散列表 (Hash Table)</h3><p>接下来我们将介绍hash table的CPU以及GPU实现。</p><p>我们先介绍一下什么是hash table。hash table是一种保存键-值二元组的数据结构，一个字典就可以被视为一个hash table。我们在使用hash table时，需要将查找某个键对应的值的时间降到最低。我们希望这是一个常量时间，即不管hash table多大，搜索某个键对应的值所需时间应该是不变的。</p><p>hash table根据值相应的键，把值放入到“桶(bucket)”中。这种将键映射到值的方法通常被称为散列函数(Hash Function)。对于理想的hash function，每个键都会被映射到一个不同的桶。然而，当多个键被映射到同一个桶中时，我们需要将桶中的所有值保存到一个链表里，每当同一个桶添加新的值时，就将新的值添加到链表的末尾。</p><h4 id="CPU散列表"><a href="#CPU散列表" class="headerlink" title="CPU散列表"></a>CPU散列表</h4><p>我们将分配一个长度为N的数组，并且数组中的每个元素都表示一个键-值二元链表。下面是实现的数据结构：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Entry</span>&#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> key;</span><br><span class="line">    <span class="type">void</span>* value;</span><br><span class="line">    Entry* next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Table</span>&#123;</span></span><br><span class="line">    <span class="type">size_t</span> count;</span><br><span class="line">    Entry** entries;</span><br><span class="line">    Entry* pool;</span><br><span class="line">    Entry* firstFree;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Entry结构中包含了键和值。在应用程序中，键是无符号整数。与键相关的值可以是任意数据类型，因此我们将value声明为一个void*变量。程序重点是介绍如何创建hash table数据结构，因此在value域中并不保存任何内容，仅保证完整性。结构Entry最后的一个成员是指向下一个Entry节点的指针。在遇到冲突时，在同一个桶中将包含多个Entry节点，因此我们决定将这些对象保存为一个链表。所以每个对象都指向桶中的下一个节点，从而形成一个节点链表。最后一个Entry节点的next指针为NULL。</p><p>本质上，table结构本身是一个“桶”数组，这个桶数组是一个长度为count的数组，其中entries中的每个桶都是指向某Entry的指针。如果每添加一个Entry节点时都分配新的内存，那么将对程序性能产生负面的影响。为了避免这种情况，hash table将在成员pool中维持一个可用Entry节点的数组。firstFree指向下一个可用的Entry节点，因此当需要将一个节点添加到hash table时，只需使用由firstFree指向的Entry然后递增这个指针，就能避免新分配内存，而且只需要free()一次就能释放所有这些节点。</p><p>下面是其他的支持代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">initialize_table</span><span class="params">(Table &amp;table, <span class="type">int</span> entries, <span class="type">int</span> elements)</span> &#123;</span><br><span class="line">    table.count = entries;</span><br><span class="line">    table.entries = (Entry**)<span class="built_in">calloc</span>( entries, <span class="keyword">sizeof</span>(Entry*) );</span><br><span class="line">    table.pool = (Entry*)<span class="built_in">malloc</span>( elements * <span class="keyword">sizeof</span>( Entry ) );</span><br><span class="line">    table.firstFree = table.pool;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在hash table初始化的过程中，主要的操作包括为桶数组entries分配内存，我们也为节点池分配了内存，并将指针firstFree初始化为指向节点池数组中的第一个节点。程序末尾释放内存时将释放桶数组和空闲节点池:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">free_table</span><span class="params">(Table &amp;table)</span>&#123;</span><br><span class="line">    <span class="built_in">free</span>(table.entries);</span><br><span class="line">    <span class="built_in">free</span>(table.pool);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在本示例中，我们采取了无符号整数作为键，并且需要将这些键映射到桶数组的索引。也就是说，将节点e保存在table.entries[e.key]中。然而，我们需要确保键的取值范围将小于桶数组的长度。下面是解决方法：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> <span class="title function_">hash</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span> key, <span class="type">size_t</span> count)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> key % count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的实现方式是将键对数组长度取模，实际情况会更复杂，这里仅仅作为示例程序来展示。我们将随机生成键，如果我们假设随机数值生成器生成的值大致是平均的，那么这个hash function应该将这些键均匀地映射到hash table的所有桶中。真正的实际情况中我们可能需要创建更为复杂的hash function。</p><p>将键值二元数组添加到hash table中包括三个基本的步骤:</p><ol><li>将键放入hash function中计算出新节点所属的桶。</li><li>从节点池中取出一个预先分配的Entry节点，初始化该节点的key和value等变量。</li><li>将这个节点插入到计算得到的桶的链表首部。</li></ol><p>下面是实现的代码:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">add_to_table</span><span class="params">(Table &amp;table, <span class="type">unsigned</span> <span class="type">int</span> key, <span class="type">void</span>* value)</span>&#123;</span><br><span class="line">    <span class="comment">// step 1</span></span><br><span class="line">    <span class="type">size_t</span> hashValue = hash(key, table.count);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// step 2</span></span><br><span class="line">    Entry* location = table.firstFree++;</span><br><span class="line">    location-&gt;key = key;</span><br><span class="line">    location-&gt;value = value;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// step 3</span></span><br><span class="line">    location-&gt;next = table.entries[hashValue];</span><br><span class="line">    table.entries[hashValue] = location;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>步骤3可能会有点难理解。链表的第一个节点是储存在了table.entries[hashValue]中，我们需要在链表的头节点中插入一个新的节点(如果在链表的末尾插入新的节点的话则需要对链表进行遍历直到末尾，增加了复杂度): 首先将新节点的next指针设置为指向链表的第一个节点，然后再将新节点保存到桶数组中(桶数组保存的是链表的第一个节点)，这样就完成了。</p><p>为了判断这段代码能否工作，我们实现了一个函数对hash table执行完好性检查。检查过程中首先遍历这张表并查看每个节点。将节点的键放入到hash function进行计算，并确认这个节点被保存到正确的桶中。在检查了每个节点后，还要验证hash table中的节点数量确实等于添加到hash table的节点数量。如果这些数值并不相等，那么要么是无意中将一个节点添加到多个桶，要么没有正确的插入节点。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> SIZE (100 * 1024 * 1024)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ELEMENTS (size / sizeof(unsigned int))</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">verify_table</span><span class="params">(<span class="type">const</span> Table &amp;table)</span>&#123;</span><br><span class="line">    <span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; table; i++)&#123;</span><br><span class="line">        Entry* current = table.entries[i];</span><br><span class="line">        <span class="keyword">while</span>(current != <span class="literal">NULL</span>)&#123;</span><br><span class="line">            count++;</span><br><span class="line">            <span class="keyword">if</span>(hash(current-&gt;value, table.count) != i)&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%d hashed to %ld, but was located at %ld\n&quot;</span>, current-&gt;value, hash(current-&gt;value, table.count), i);</span><br><span class="line">                current = current-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(count != ELEMENTS)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%d elements found in hash table. Should be %ld\n&quot;</span>, count, ELEMENTS);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;All %d elements found in hash table.\n&quot;</span>, count);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于大部分的功能实现都放到了函数中，因此main()函数就相对比较简单:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> HASH_ENTRIES 1024</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">unsigned</span>* buffer = (<span class="type">unsigned</span> <span class="type">int</span>*)big_random_block(SIZE);</span><br><span class="line">    <span class="type">clock_t</span> start, stop;</span><br><span class="line">    start = clock();</span><br><span class="line">    </span><br><span class="line">    Table table;</span><br><span class="line">    initialize_table(table, HASH_ENTRIES, ELEMENTS);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; ELEMENTS; i++)&#123;</span><br><span class="line">        add_to_table(table, buffer[i], (<span class="type">void</span>*)<span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    stop = clock();</span><br><span class="line">    <span class="type">float</span> elapsedTime = (<span class="type">float</span>)(stop - start) / (<span class="type">float</span>)CLOCK_PER_SEC * <span class="number">1000.0f</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time to hash: %3.1f ms\n&quot;</span>, elapsedTime);</span><br><span class="line">    </span><br><span class="line">    verify_table(table);</span><br><span class="line">    free_table(table);</span><br><span class="line">    <span class="built_in">free</span>(buffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们首先分配了一大块内存来保存随机数值。这些随机生成的无符号整数将被作为插入到hash table中的键。在生成了这些数值后，接下来将读取系统时间以便统计程序的性能。我们对hash table进行初始化，然后通过for循环将每个随机键插入到hash table。在添加了所有的键后，再次读取系统时间，通过之前读取的系统时间与这次系统时间就可以计算出在初始化和添加键上花费的时间。最后，我们通过完整性检查函数来验证hash table，并且释放了分配的内存。</p><h4 id="多线程环境下的hash-table"><a href="#多线程环境下的hash-table" class="headerlink" title="多线程环境下的hash table"></a>多线程环境下的hash table</h4><p>多线程环境下的hash table可能会遇到race condition。那么如何在GPU上构建一个hash table呢？在点积示例中，每次只有一个线程可以安全地将它的值与最终结果相加。如果每个桶都有一个原子锁，那么我们可以确保每次只有一个线程对指定的桶进行修改。</p><h4 id="GPU-hash-table"><a href="#GPU-hash-table" class="headerlink" title="GPU hash table"></a>GPU hash table</h4><p>在有了某种方法来确保对hash table实现安全的多线程访问，我们就可以实现GPU的hash table的应用程序。我们需要使用Lock，还需要把hash function声明为一个__device__函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/book.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;lock.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Entry</span>&#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> key;</span><br><span class="line">    <span class="type">void</span>* value;</span><br><span class="line">    Entry* next;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Table</span>&#123;</span></span><br><span class="line">    <span class="type">size_t</span> count;</span><br><span class="line">    Entry** entries;</span><br><span class="line">    Entry* pool;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __host__ <span class="type">size_t</span> <span class="title function_">hash</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span> value, <span class="type">size_t</span> count)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value % count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当__host__与__device__关键字一起使用时，将告诉NVIDIA编译器同时生成函数在设备和主机上的版本。设备版本的函数将在设备上运行，并且只能从设备代码中调用。主机版本的函数将在主机上运行，并且只能从主机代码中调用。__host__与__device__关键字一起使用可以让这个函数既可以在设备上使用又可以在主机上使用。</p><p>initialize_table()和free_table()与CPU版本差别不大，只是数组的初始化以及释放的代码修改成的GPU版本:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">initialize_table</span><span class="params">(Table &amp;table, <span class="type">int</span> entries, <span class="type">int</span> elements)</span>&#123;</span><br><span class="line">    table.count = entries;</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;table.entries, entries * <span class="keyword">sizeof</span>(Entry*)));</span><br><span class="line">    HANDLE_ERROR(cudaMemset(table.entries, <span class="number">0</span>, entries * <span class="keyword">sizeof</span>(Entry*)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;table.pool, elements * <span class="keyword">sizeof</span>(Entry)));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">free_table</span><span class="params">(Table &amp;table)</span>&#123;</span><br><span class="line">    cudaFree(table.pool);</span><br><span class="line">    cudaFree(table.entries);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>verify_table()的CPU版本和GPU版本相同，仅仅需要在开头增加一个函数将hash table从GPU复制到CPU。下面是将hash table从GPU复制到CPU的代码:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">copy_table_to_host</span><span class="params">(<span class="type">const</span> Table &amp;table, Table &amp;hostTable)</span>&#123;</span><br><span class="line">    hostTable.count = table.count;</span><br><span class="line">    hostTable.entries = (Entry**)<span class="built_in">calloc</span>(table.count, <span class="keyword">sizeof</span>(Entry*));</span><br><span class="line">    hostTable.pool = (Entry*)<span class="built_in">malloc</span>(ELEMENTS * <span class="keyword">sizeof</span>(Entry));</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(hostTable.entries, table.entries, table.count * <span class="keyword">sizeof</span>(Entry*), cudaMemcpyDeviceToHost));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(hostTable.pool, table.pool, ELEMENTS * <span class="keyword">sizeof</span>(Entry), cudaMemcpyDeviceToHost));</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在复制的数据中，有一部分数据是指针。我们不能简单地将这些指针复制到主机，<strong>因为这些指针指向的地址是在GPU上，它们在主机上并不是有效的指针</strong>。然而，这些<strong>指针的相对偏移量</strong>仍然是有效的。每个指向Entry节点的GPU指针都指向数组table.pool[]中的某个位置，但为了在主机上使用hash table，我们需要它们指向数组hostTable.pool[]中相同的Entry。</p><p>给定一个GPU的指针X，需要将这个指针相对于table.pool的偏移与hostTable.pool相加，从而获得一个有效的主机指针，新指针应该按照以下公式计算:<br>$$<br>(X - table.pool) + hostTable.pool<br>$$<br>对于每个被复制的Entry指针，都要执行这个更新操作：包括hostTable.entries中的Entry指针，以及hash table的节点池中每个Entry的next指针:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; table.count; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(hostTable.entries[i] != <span class="literal">NULL</span>)&#123;</span><br><span class="line">            hostTable.entries[i] = (Entry*)((<span class="type">size_t</span>)hostTable.entries[i] - (<span class="type">size_t</span>)table.pool + (<span class="type">size_t</span>)hostTable.pool);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; ELEMENTS; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(hostTable.pool[i].next != <span class="literal">NULL</span>)&#123;</span><br><span class="line">            hostTable.pool[i].next = (Entry*)((<span class="type">size_t</span>)hostTable.pool[i].next - (<span class="type">size_t</span>)table.pool + (<span class="type">size_t</span>)hostTable.pool);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在介绍完了数据结构、hash function、初始化过程、内存释放过程以及验证代码后，还剩下的重要部分就是CUDA C原子语句的使用。核函数add_to_table()的参数包括一个键数组、一个值数组、hash table本身以及一个lock数组。这些数组将被用于锁定hash table中的每个桶。由于输入的数据是两个数组，并且在线程中需要对这两个数组进行索引，因此还需要将索引线性化:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__global_ <span class="type">void</span> <span class="title function_">add_to_table</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span>* keys, <span class="type">void</span>** values, Table table, Lock* lock)</span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br></pre></td></tr></table></figure><p>线程会像点积示例那样遍历输入数组。对于数组key[]中的每个键，线程都将通过hash function计算出这个键值二元数组属于哪个桶。在计算出目标桶之后，线程会锁定这个桶，添加它的键值二元组，然后解锁这个桶。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">while</span>(tid &lt; ELEMENTS)&#123;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">int</span> key = keys[tid];</span><br><span class="line">        <span class="type">size_t</span> hashValue = hash(key, table.count);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>((tid % <span class="number">32</span>) == i)&#123;</span><br><span class="line">                Entry* location = &amp;(table.pool[tid]);</span><br><span class="line">                location-&gt;key = key;</span><br><span class="line">                location-&gt;value = values[tid];</span><br><span class="line">                lock[hashVaue].lock();</span><br><span class="line">                location-&gt;next = table.entries[hashValue];</span><br><span class="line">                table.entries[hashValue] = location;</span><br><span class="line">                lock[hashValue].unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        tid += stride;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>for循环和后面的if语句看上去是不必要的。然而，代码中的线程束是一个包含32线程的集合，并且这些线程以步调一致的方式执行。每次在线程束中只有一个线程可以获取这个锁。如果让线程束中的所有32给线程都同时竞争这个锁，那么将会发生严重的问题。这种情况下，最好的方式就是在软件中执行一部分工作，遍历线程束中的线程，并给每个线程一次机会来获取数据结构的锁，执行它的工作，然后释放锁。</p><p>main函数的执行流程跟CPU版本的相似:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span>* buffer = (<span class="type">unsigned</span> <span class="type">int</span>*)big_random_block(SIZE);</span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span>* dev_keys;</span><br><span class="line">    <span class="type">void</span>** dev_values;</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_keys, SIZE));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_values, SIZE));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_keys, buffer, SIZE, cudaMemcpyHostToDevice));</span><br><span class="line">    </span><br><span class="line">    Table table;</span><br><span class="line">    initialize_table(table, HADH_ENTRIES, ELEMENTS);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 声明一个锁数组，数组中的每个锁对应于桶数组中的每个桶。并将它们复制到GPU上。</span></span><br><span class="line">    Lock lock[HASH_ENTRIES];</span><br><span class="line">    Lock* dev_lock;</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_lock, HASH_ENTRIES * <span class="keyword">sizeof</span>(Lock)));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_lock, lock, HASH_ENTRIES * <span class="keyword">sizeof</span>(Lock), cudaMemcpyHostToDevice));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 将键添加到hash table，停止性能计数器，验证hash table的正确性，执行释放工作</span></span><br><span class="line">    add_to_table&lt;&lt;&lt;<span class="number">60</span>, <span class="number">256</span>&gt;&gt;&gt;(dev_keys, dev_values, tavle, dev_lock);</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time to hash: 3%3.1f ms\n&quot;</span>, elapsedTime);</span><br><span class="line">    </span><br><span class="line">    verify_table(table);</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(stop));</span><br><span class="line">    free_table(table);</span><br><span class="line">    cudaFree(Dev_lock);</span><br><span class="line">    cudaFree(dev_keys);</span><br><span class="line">    cudaFree(dev_values);</span><br><span class="line">    <span class="built_in">free</span>(buffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/03/09/CUDA%E5%AD%A6%E4%B9%A0-%E4%B9%9D/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(八)</title>
      <link>http://example.com/2024/02/29/CUDA%E5%AD%A6%E4%B9%A0-%E5%85%AB/</link>
      <guid>http://example.com/2024/02/29/CUDA%E5%AD%A6%E4%B9%A0-%E5%85%AB/</guid>
      <pubDate>Thu, 29 Feb 2024 04:14:49 GMT</pubDate>
      
      <description>&lt;p&gt;本章将介绍如何分配和使用零拷贝内存(Zero-Copy Memory)，如何在同一个应用程序中使用多个GPU，以及如何分配和使用可移动的固定内存(Portable Pinned Memory)。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本章将介绍如何分配和使用零拷贝内存(Zero-Copy Memory)，如何在同一个应用程序中使用多个GPU，以及如何分配和使用可移动的固定内存(Portable Pinned Memory)。</p><span id="more"></span><h2 id="零拷贝主机内存"><a href="#零拷贝主机内存" class="headerlink" title="零拷贝主机内存"></a>零拷贝主机内存</h2><p>上一章介绍了固定内存（页锁定内存），这种新型的主机内存能够确保不会交换出物理内存。我们通过cudaHostAlloc()来分配这种内存，并且传递参数cudaHostAllocDefault来获得默认的固定内存。本章会介绍在分配固定内存时可以使用其他参数值。除了cudaHostAllocDefault外，还可以传递的标志之一是cudaHostAllocMapped。通过cudaHostAllocMapped分配的主机内存也是固定的，它与通过cudaHostAllocDefault分配的固定内存有着相同的属性，特别是当它不能从物理内存中交换出去或者重新定位时。但这种内存除了可以用于主机与GPU之间的内存复制外，还可以打破主机内存规则之一：可以在CUDA C核函数中直接访问这种类型的主机内存。由于这种内存不需要复制到GPU，因此也被称为零拷贝内存。</p><h3 id="通过零拷贝内存实现点积运算"><a href="#通过零拷贝内存实现点积运算" class="headerlink" title="通过零拷贝内存实现点积运算"></a>通过零拷贝内存实现点积运算</h3><p>通常，GPU只能访问GPU内存，而CPU也只能访问主机内存。但在某些环境中，打破这种规则或许能带来更好的效果。下面仍然给出一个矢量点积运算来进行介绍。这个版本不将输入矢量显式复制到GPU，而是使用零拷贝内存从GPU中直接访问数据。我们将编写两个函数，其中一个函数是对标准主机内存的测试，另一个函数将在GPU上执行归约运算，并使用零拷贝内存作为输入缓冲区和输出缓冲区。首先是点积运算的主机内存版本:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> <span class="title function_">malloc_test</span><span class="params">(<span class="type">int</span> size)</span>&#123;</span><br><span class="line">    <span class="comment">//首先创建计时事件，然后分配输入缓冲区和输出缓冲区，并用数据填充输入缓冲区。</span></span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">float</span> *a, *b, c, *partial_c;</span><br><span class="line">    <span class="type">float</span> *dev_a, *dev_b, *dev_partial_c;</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在CPU上分配内存</span></span><br><span class="line">    a = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    b = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    partial_c = (<span class="type">float</span>*)<span class="built_in">malloc</span>(blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_b, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//用数据填充主机内存</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++)&#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = i * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//启动计时器，将输入数据复制到GPU，执行点积核函数，并将中间计算结果复制回主机。</span></span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    <span class="comment">//将数组“a“和”b”复制到GPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_a, a, size * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_b, b, size * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(size, dev_a, dev_b, dev_partial_c);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数组“c”从GPU复制到CPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDeviceToHost));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//停止计时器</span></span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将中间计算结果相加起来，并释放输入缓冲区和输出缓冲区</span></span><br><span class="line">    <span class="comment">//结束CPU上的计算</span></span><br><span class="line">    c = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; blocksPerGrid; i++)&#123;</span><br><span class="line">        c += partial_c[i];</span><br><span class="line">    &#125;</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_a));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_b));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_partial_c));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//释放CPU上的内存</span></span><br><span class="line">    <span class="built_in">free</span>(a);</span><br><span class="line">    <span class="built_in">free</span>(b);</span><br><span class="line">    <span class="built_in">free</span>(partial_c);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//释放事件</span></span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(stop));</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Value calculated: %f\n&quot;</span>, c);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> elapsedTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用零拷贝内存的版本是非常类似的多，只是在内存分配上有所不同：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> <span class="title function_">cuda_host_alloc_test</span><span class="params">(<span class="type">int</span> size)</span>&#123;</span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">float</span> *a, *b, c, *partial_c;</span><br><span class="line">    <span class="type">float</span> *dev_a, *dev_b, *dev_partial_c;</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在CPU上分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;a, size * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaHostAllocWriteCombined | cudaHostAllocMapped));</span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;b, size * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaHostAllocWriteCombined | cudaHostAllocMapped));</span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaHostAllocMapped));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//用数据填充主机内存</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++)&#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = i * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用cudaHostAlloc()时，通过参数flags来指定内存的其他行为。cudaHostAllocMapped这个标志告诉运行时将从GPU中访问这块内存。这个标志意味着分配零拷贝内存。对于这两个输入缓冲区，我们还制定了标志cudaHostAllocWriteCombined。这个标志运行时应该将内存分配为“合并式写入（Write-Combined）”内存。这个标志并不会改变应用程序的功能，但却可以显著地提升GPU读取内存时的性能。然而，当CPU也要读取这块内存时，“合并式写入”会显得低效，因此在决定是否使用这个标志之前，必须首先考虑应用程序的可能访问模式。</p><p>在使用标志cudaHostAllocMapped来分配主机内存后，就可以从GPU中访问这块内存。然而，GPU的虚拟内存空间与CPU是不同的，因此在<strong>GPU上访问它们与在CPU上访问它们有着不同的地址。调用cudaHostAlloc()将返回这块内存在CPU上的指针，因此需要调用cudaHostGetDevicePointer()来获得这块内存在GPU上的有效指针。</strong>这些指针将被传递给核函数，并在随后由GPU对这块内存执行读取和写入等操作。即使dev_a、dev_b和dev_partial_c都位于主机上，但对于核函数来说，它们看起来就像GPU内存一样，这正是由于调用了cudaHostGetDevicePointer()。由于部分计算结果已经位于主机上，<strong>因此就不再需要通过cudaMemcpy()将它们从设备上复制回来。</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">    HANDLE_ERROR(cudaHostGetDevicePointer(&amp;dev_a, a, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaHostGetDevicePointer(&amp;dev_b, b, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaHostGetDevicePointer(&amp;dev_partial_c, partial_c, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//启动计时器以及核函数</span></span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(size, dev_a, dev_b, dev_partial_c);</span><br><span class="line">    <span class="comment">//不再需要通过cudaMemcpy()将它们从设备上复制回来</span></span><br><span class="line">    HANDLE_ERROR(cudaThreadSynchronize());</span><br><span class="line"></span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//结束GPU上的操作</span></span><br><span class="line">    c = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; blocksPerGrid; i++)&#123;</span><br><span class="line">        c += partial_c[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在使用cudaHostAlloc()的点积运算代码中，唯一剩下的事情就是执行释放操作</span></span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(a));</span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(b));</span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(partial_c));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放事件</span></span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(stop));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Value calculated: %f\n&quot;</span>, c);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> elapsedTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>无论cudaHostAlloc()中使用什么标志，总是按照相同的方式来释放内存，即只需调用cudaFreeHost()。剩下的工作就是观察main()如何将这些代码片段组合在一起。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    cudaDeviceProp prop;</span><br><span class="line">    <span class="type">int</span> which Device;</span><br><span class="line">    HANDLE_ERROR(cudaGetDevice(&amp;whichDevice));</span><br><span class="line">    HANDLE_ERROR(cudaGetDeviceProperties(&amp;prop, whichDevice));</span><br><span class="line">    <span class="keyword">if</span>(prop.canMapHostMemory != <span class="number">1</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Device, cannot map memory. \n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//如果设备支持零拷贝内存，那么接下来就是将运行时置入能分配零拷贝内存的状态</span></span><br><span class="line">    <span class="comment">//通过调用cudaSetDeviceFlags()来实现这个操作，并且传递标志值cudaDeviceMapHost来表示我们希望设备映射主机内存</span></span><br><span class="line">    HANDLE_ERROR(cudaSetDeviceFlags(cudaDeviceMapHost));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//运行两个测试，分别显示二者的执行时间，并推出应用程序：</span></span><br><span class="line">    <span class="type">float</span> elapsedTime = malloc_test(N);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time using cudaMalloc: %3.1f ms\n&quot;</span>, elapsedTime);</span><br><span class="line">    elapsedTime = cuda_host_alloc_test(N);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time using cudaHostAlloc: %3.1f ms\n&quot;</span>, elapsedTime);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是给出的核函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> imin(a, b) (a &lt; b ? a : b)</span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">33</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> blocksPerGrid = imin(<span class="number">32</span>, (N + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock);</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">dot</span><span class="params">(<span class="type">int</span> size, <span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">float</span> *c)</span>&#123;</span><br><span class="line">    __shared__ <span class="type">float</span> cache[threadsPerBlock];</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> cacheIndex = threadIdx.x;</span><br><span class="line">    <span class="type">float</span> temp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(tid &lt; size)&#123;</span><br><span class="line">        temp += a[tid] * b[tid];</span><br><span class="line">        tid += blockDim.x * gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//设置cache中的值</span></span><br><span class="line">    cache[cacheIndex] = temp;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//同步这个线程块中的线程</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//对于归约运算， threadsPerBlock必须为2的幂</span></span><br><span class="line">    <span class="type">int</span> i = blockDim.x / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span>(i != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(cacheIndex &lt; i)&#123;</span><br><span class="line">            cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        i /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(cacheIndex == <span class="number">0</span>)&#123;</span><br><span class="line">        c[blockIdx.x] = cache[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用多个GPU"><a href="#使用多个GPU" class="headerlink" title="使用多个GPU"></a>使用多个GPU</h2><p>我们将把点积应用程序修改为使用多个GPU。为了降低编码难度，我们将在上一个结构中把计算点积所需的全部数据都相加起来。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">DataStruct</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> deviceID;</span><br><span class="line">    <span class="type">int</span> size;</span><br><span class="line">    <span class="type">float</span> *a;</span><br><span class="line">    <span class="type">float</span> *b;</span><br><span class="line">    <span class="type">float</span> returnValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个结构包含了在计算点积时使用的设备标识，以及输入缓冲区的大小和指向两个输入缓冲区的指针a和b。最后，它还包含了一个成员用于保存a和b的点积运算结果。</p><p>要使用N个GPU，我们首先需要准确地知道N值是多少。因此，在应用程序的开头调用cudaDeviceCount()，从而判断在系统中安装了多少个支持CUDA的处理器。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> deviceCount;</span><br><span class="line">    HANDLE_ERROR(cudaGetDeviceCount(&amp;deviceCount));</span><br><span class="line">    <span class="keyword">if</span>(deviceCount &lt; <span class="number">2</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;We need at least two compute 1.0 or greater devices, but only found %d\n&quot;</span>, deviceCount);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//为输入缓冲区分配标准的主机内存，并按照之前的方式填充</span></span><br><span class="line">    <span class="type">float</span> *a = (<span class="type">float</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">float</span>) * N);</span><br><span class="line">    HANDLE_NULL(a);</span><br><span class="line">    <span class="type">float</span> *b = (<span class="type">float</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">float</span>) * N);</span><br><span class="line">    HANDLE_NULL(b);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//用数据填充主机内存</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = i * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>通过CUDA运行API来使用多个GPU时，要意识到每个GPU都需要由一个不同的CPU线程来控制。由于之前只是用了单个GPU，因此不需要担心这个问题。我们将多线程代码的大部分复杂性都移入到辅助代码文件book.h中。在精简了代码后，我们需要做的就是填充一个结构来执行计算。虽然在系统中可以有任意数量的GPU，但为了简单，在这里只使用两个：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">DataStruct data[<span class="number">2</span>];</span><br><span class="line"></span><br><span class="line">data[<span class="number">0</span>].deviceID = <span class="number">0</span>;</span><br><span class="line">data[<span class="number">0</span>].size = N / <span class="number">2</span>;</span><br><span class="line">data[<span class="number">0</span>].a = a;</span><br><span class="line">data[<span class="number">0</span>].b = b;</span><br><span class="line"></span><br><span class="line">data[<span class="number">1</span>].deviceID = <span class="number">1</span>;</span><br><span class="line">data[<span class="number">1</span>].size = N / <span class="number">2</span>;</span><br><span class="line">data[<span class="number">1</span>].a = a + N / <span class="number">2</span>;</span><br><span class="line">data[<span class="number">1</span>].b = b + N / <span class="number">2</span>;</span><br></pre></td></tr></table></figure><p>我们将其中一个DataStruct变量传递给辅助函数start_thread()。此外，还将一个函数指针传给了start_thread()，新创建的线程将调用这个函数，这个示例中的线程函数为routine()。函数start_thread()将创建一个新的线程，这个线程将调用routine()，并将DataStruct变量作为参数传递进去。在应用程序的默认线程中也将调用routine()(因此只多创建了一个线程)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">    CUTThread thread = start_thread(routine, &amp;(data[<span class="number">0</span>]));</span><br><span class="line">    routine(&amp;(data[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过调用end_thread()，主应用程序线程将等待另一个线程执行完成。</span></span><br><span class="line">    end_thread(thread);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//由于这两个线程都在main()的这个位置上执行完成，因此可以安全地释放内存并显示结果。</span></span><br><span class="line">    <span class="built_in">free</span>(a);</span><br><span class="line">    <span class="built_in">free</span>(b);</span><br><span class="line"></span><br><span class="line"><span class="comment">//我们要将每个线程的计算结果相加起来。</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Value calculated: %f\n&quot;</span>, data[<span class="number">0</span>].returnValue + data[<span class="number">1</span>].returnValue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在声明routine()时指定该函数带有一个void*参数，并返回void*，这样在start_thread()部分代码保持不变的情况下可以任意实现线程函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span>* <span class="title function_">routine</span><span class="params">(<span class="type">void</span> *pvoidData)</span>&#123;</span><br><span class="line">    DataStruct *data = (DataStruct*)pvoidData;</span><br><span class="line">    HANDLE_ERROR(cudaSetDevice(data-&gt;deviceID));</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>除了调用cudaSetDevice()来指定希望使用的CUDA设备外，routine()的实现非常类似于之前提到的malloc_test()。我们为输入数据和临时计算结果分别分配了内存，随后调用cudaMemcpy()将每个输入数组复制到GPU。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">    <span class="type">int</span> size = data-&gt;size;</span><br><span class="line">    <span class="type">float</span> *a, *b, c, *partial_c;</span><br><span class="line">    <span class="type">float</span> *dev_a, *dev_b, *dev_partial_c;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在CPU上分配内存</span></span><br><span class="line">    a = data-&gt;a;</span><br><span class="line">    b = data-&gt;b;</span><br><span class="line">    partial_c = (<span class="type">float</span>*)<span class="built_in">malloc</span>(blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在GPU上分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_b, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数组“a”和“b”复制到GPU上</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_a, a, size * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_b, b, size * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//启动点积核函数，复制回计算结果，并且结束CPU上的操作</span></span><br><span class="line">    dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(size, dev_a, dev_b, dev_partial_c);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数组“c”从GPU复制回CPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDeviceToHost));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//结束CPU上的操作</span></span><br><span class="line">    c = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; blocksPerGrid; i++)&#123;</span><br><span class="line">        c += partial_c[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_a));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_b));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_partial_c));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放CPU侧的内存</span></span><br><span class="line">    <span class="built_in">free</span>(partial_c);</span><br><span class="line"></span><br><span class="line">    data-&gt;returnValue = c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="可移动的固定内存"><a href="#可移动的固定内存" class="headerlink" title="可移动的固定内存"></a>可移动的固定内存</h2><p>我们可以将固定内存分配为可移动的，这意味着可以在主机线程之间移动这块内存，并且每个线程都将其视为固定内存。要达到这个目的，需要使用cudaHostAlloc()来分配内存，并且在调用时使用一个新的标志：cudaHostAllocPortable。这个标志可以与其他标志一起使用，例如cudaHostAllocWriteCombined和cudaHostAllocMapped。这意味着在分配主机内存时，可将其作为可移动、零拷贝以及合并式写入等的任意组合。</p><p>为了说明可移动固定内存的作用，我们将进一步修改使用多GPU的点积运算应用程序。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> deviceCount;</span><br><span class="line">    HANDLE_ERROR(cudaGetDeviceCount(&amp;deviceCount));</span><br><span class="line">    <span class="keyword">if</span>(deviceCount &lt; <span class="number">2</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;We need at least two compute 1.0 or greater devices, but only found %d\n&quot;</span>, deviceCount);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cudaDeviceProp prop;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++)&#123;</span><br><span class="line">        HANDLE_ERROR(cudaGetDeviceProperties(&amp;prop, i));</span><br><span class="line">        <span class="keyword">if</span>(prop.canMapHostMemory != <span class="number">1</span>)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Devide %d cannot map memory.\n&quot;</span>, i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *a, *b;</span><br><span class="line">    HANDLE_ERROR(cudaSetDevice(<span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaSetDeviceFlags(cudaDeviceMapHost));</span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;a, N * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaHostAllocWriteCombined | cudaHostAllocPortable | cudaHostAllocMapped));</span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;b, N * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaHostAllocWriteCombined | cudaHostAllocPortable | cudaHostAllocMapped));</span><br></pre></td></tr></table></figure><p>在使用cudaHostAlloc()分配页锁定内存时，首先要通过调用cudaSetDevice()来初始化设备。我们将新介绍的标志cudaHostAllocPortable传递给这两个内存分配操作。由于这些内存是在调用了cudaSetDevice(0)之后才分配的，因此，如果没有将这些内存指定为可移动的内存，那么只有第0个CUDA设备会把这些内存视为固定内存。</p><p>继续之前的应用程序，为输入矢量生成数据，并采用之前的示例的方式来准备DataStruct结构。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">//用数据填充主机内存</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = i * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//为使用多线程做好准备</span></span><br><span class="line">    DataStruct data[<span class="number">2</span>];</span><br><span class="line">    data[<span class="number">0</span>].deviceID = <span class="number">0</span>;</span><br><span class="line">    data[<span class="number">0</span>].offset = <span class="number">0</span>;</span><br><span class="line">    data[<span class="number">0</span>].size = N / <span class="number">2</span>;</span><br><span class="line">    data[<span class="number">0</span>].a = a;</span><br><span class="line">    data[<span class="number">0</span>].b = b;</span><br><span class="line"></span><br><span class="line">    data[<span class="number">1</span>].deviceID = <span class="number">1</span>;</span><br><span class="line">    data[<span class="number">1</span>].offset = N / <span class="number">2</span>;</span><br><span class="line">    data[<span class="number">1</span>].size = N / <span class="number">2</span>;</span><br><span class="line">    data[<span class="number">1</span>].a = a;</span><br><span class="line">    data[<span class="number">1</span>].b = b;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建第二个线程，并调用routine()开始在每个设备上执行计算</span></span><br><span class="line">    CUTThread thread = start_thread(routine, &amp;(data[<span class="number">1</span>]));</span><br><span class="line">    routine(&amp;(data[<span class="number">0</span>]));</span><br><span class="line">    end_thread(thread);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//由于主机内存时由CUDA运行时分配的，因此需要用cudaFreeHost()而不是free()来释放它</span></span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(a));</span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(b));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Value calculated: %f\n&quot;</span>, data[<span class="number">0</span>].returnValue + data[<span class="number">1</span>].returnValue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为了在多GPU应用程序中支持可移动的固定内存和零拷贝内存，我们需要对routine()的代码进行两处修改。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span>* <span class="title function_">routine</span><span class="params">(<span class="type">void</span> *pvoidData)</span>&#123;</span><br><span class="line">    DataStruct *data = (DataStruct*)pvoidData;</span><br><span class="line">    <span class="keyword">if</span>(data-&gt;deviceID != <span class="number">0</span>)&#123;</span><br><span class="line">        HANDLE_ERROR(cudaSetDevice(data-&gt;deviceID));</span><br><span class="line">        HANDLE_ERROR(cudaSetDeviceFlags(cudaDeviceMapHost));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>在多GPU版本的代码中，我们需要在routine()中调用cudaSetDevice()，从而确保每个线程控制一个不同的GPU。另一方面，在这个示例中，我们已经在主线程中调用了一次cudaSetDevice()。这么做的原因时为了在main()中分配固定内存。因此，我们只希望在还没有调用cudaSetDevice()的设备上调用cudaSetDevice()和cudaSetDeviceFlags()。也就是，如果devideID不是0，那么将调用这两个函数。虽然在第0个设备上再次调用这些函数会使代码更简洁，但是这种做法是错误的。一旦在某个线程上设置了这些设备，那么将不能再次调用cudaSetDevice()，即便传递的是相同的设备标识符。</p><p>除了使用可移动的固定内存外，我们还使用了零拷贝内存，一边从GPU中直接访问这些内存。因此，我们使用cudaHostGetDevicePointer()来获得主机内存的有效设备指针，这与前面零拷贝示例中采用的方法一样。然而，你可能会注意到使用了标准的GPU内存来保存临时计算结果。这块内存同样是通过cudaMalloc()来分配的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">    <span class="type">int</span> size = data-&gt;size;</span><br><span class="line">    <span class="type">float</span> *a, *b, c, *partial_c;</span><br><span class="line">    <span class="type">float</span> *dev_a, *dev_b, *dev_partial_c;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在CPU上分配内存</span></span><br><span class="line">    a = data-&gt;a;</span><br><span class="line">    b = data-&gt;b;</span><br><span class="line">    partial_c = (<span class="type">float</span>*)<span class="built_in">malloc</span>(blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">    HANDLE_ERROR(cudaHostGetDevicePointer(&amp;dev_a, a, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaHostGetDevicePointer(&amp;dev_b, b, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计算GPU读取数据的偏移量“a”和“b”</span></span><br><span class="line">    dev_a += data-&gt;offset;</span><br><span class="line">    dev_b += data-&gt;offset;</span><br><span class="line">    dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(size, dev_a, dev_b, dev_partial_c);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数组“c“从GPU复制回CPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDeviceToHost));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//结束在CPU上的操作</span></span><br><span class="line">    c = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; blocksPerGrid; i++)&#123;</span><br><span class="line">        c += partial_c[i];</span><br><span class="line">    &#125;</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_partial_c));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放CPU上的内存</span></span><br><span class="line">    <span class="built_in">free</span>(partial_c);</span><br><span class="line"></span><br><span class="line">    data-&gt;returnValue = c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/02/29/CUDA%E5%AD%A6%E4%B9%A0-%E5%85%AB/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(七)</title>
      <link>http://example.com/2024/02/28/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%83/</link>
      <guid>http://example.com/2024/02/28/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%83/</guid>
      <pubDate>Wed, 28 Feb 2024 01:53:54 GMT</pubDate>
      
      <description>&lt;p&gt;在并行环境中，任务可以是任意操作。例如，应用程序可以执行两个任务：其中一个线程重绘程序的GUI，而另一个线程通过网络下载更新包。这些任务并行执行，彼此之间没有任何共同的地方。虽然GPU上的任务并行性并不像CPU上的任务并行性那样灵活，但仍然可以进一步提高程序在GPU上的运行速度。本章将介绍CUDA流，以及如何通过流在GPU上同时执行多个任务。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>在并行环境中，任务可以是任意操作。例如，应用程序可以执行两个任务：其中一个线程重绘程序的GUI，而另一个线程通过网络下载更新包。这些任务并行执行，彼此之间没有任何共同的地方。虽然GPU上的任务并行性并不像CPU上的任务并行性那样灵活，但仍然可以进一步提高程序在GPU上的运行速度。本章将介绍CUDA流，以及如何通过流在GPU上同时执行多个任务。</p><span id="more"></span><h2 id="页锁定-Page-Locked-主机内存"><a href="#页锁定-Page-Locked-主机内存" class="headerlink" title="页锁定(Page-Locked)主机内存"></a>页锁定(Page-Locked)主机内存</h2><p>CUDA提供了自己独有的机制来分配主机内存：cudaHostAlloc()。malloc()分配的内存与cudaHostAlloc()分配的内存之间存在一个重要差异。C库函数malloc()将分配标准的、可分页的(Pagable)主机内存，而cudaHostAlloc()将分配页锁定的主机内存。页锁定内存也称为固定内存(Pinned Memory)或者不可分页内存，它有一个重要属性：操作系统将不会对这块内存分页并交还到磁盘上，从而确保了该内存始终驻留在物理内存中。因此，操作系统能够安全地使某个应用程序访问该内存的物理地址，因为这块内存将不会被破坏或者重新定位。</p><p>由于GPU知道内存的物理地址，因此可以通过“直接内存访问（Direct Memory Access，DMA）”技术来在GPU和主机之间复制数据。由于DMA在执行复制时无需CPU的介入，这也就意味着，CPU很可能在DMA的执行过程中将目标内存交换到磁盘上，或者通过更新操作系统的分页来重新定位目标内存的物理地址。CPU可能会移动可分页的数据，这就可能对DMA操作造成延迟。因此，在DMA复制过程中使用固定内存时非常重要的。</p><p>事实上，当使用可分页内存进行复制时，CUDA驱动程序仍然会通过DAM把数据传输给GPU。因此，复制操作将执行两遍，第一遍从可分页内存复制到一块“临时的”页锁定内存，然后再从这个页锁定内存复制到GPU上。因此，<strong>每当从可分页内存中执行复制操作时，复制速度将受限于PCIE（高速串行计算机扩展总线标准）传输速度和系统前端总线速度相对较低的一方。当在GPU和主机间复制数据时，这种差异会使页锁定主机内存的性能比标准可分页内存的性能要高达约2倍。</strong>计时PCIE的速度与前端总线的速度相等，由于可分页内存需要更多一次由CPU参与的复制操作，因此会带来额外的开销。</p><p>然而，使用cudaHostAlloc()分配固定内存时，将失去虚拟内存的所有功能。特别是在应用程序中使用每个页锁定内存时都需要分配物理内存，因为这些内存不能交换到磁盘上。这意味着与使用标准的malloc()调用相比，系统将更快地耗尽内存。因此，应用程序在物理内存较少的机器上会运行失败，而且意味着应用程序将影响在系统上运行的其他应用程序的性能。建议仅对cudaMemcpy()调用中的源内存或者目标内存才使用页锁定内存，并且在不再需要使用它们时立即释放，而不是等到应用程序关闭时才释放。</p><p>下面给的例子来说明如何分配固定内存，以及它相对于标准可分页内存的性能优势。这个例子主要是测试cudaMemcpy()在可分配内存和页锁定内存上的性能。我们要做的就是分配一个GPU缓冲区以及一个大小相等的主机缓冲区，然后两个缓冲区之间执行一些复制操作（从主机到设备、从设备到主机）。为了获得精确的时间统计，我们为复制操作的起始时刻和结束时刻分别设置了CUDA事件。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> <span class="title function_">cuda_malloc_test</span><span class="params">(<span class="type">int</span> size, <span class="type">bool</span> up)</span>&#123;</span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">int</span> *a, *dev_a;</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    </span><br><span class="line">    a = (<span class="type">int</span>*)<span class="built_in">malloc</span>(size * <span class="keyword">sizeof</span>(*a));</span><br><span class="line">    HANDLE_NULL(a);</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a, size * <span class="keyword">sizeof</span>(&amp;dev_a)));</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cuddaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//为size个整数分别分配主机缓冲区和GPU缓冲区，然后执行100次复制操作，并由参数up来指定复制方向，在完成复制操作后停止计时器</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(up)&#123;</span><br><span class="line">            HANDLE_ERROR(cudaMemcpy(dev_a, a, size * <span class="keyword">sizeof</span>(*dev_a), cudaMemcpyHostToDevice));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            HANDLE_ERROR(cudaMemcpy(a, dev_a, size * <span class="keyword">sizeof</span>(*dev_a), cudaMemcpyDeviceToHost));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">free</span>(a);</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_a));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(stop));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> elapsedTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数cuda_malloc_test()通过标准的C函数malloc()来分配可分页主机内存，在分配固定内存时则使用了cudaHostAlloc()。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> <span class="title function_">cuda_host_alloc_test</span><span class="params">(<span class="type">int</span> size, <span class="type">bool</span> up)</span>&#123;</span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">int</span> *a, *dev_a;</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;a, size * <span class="keyword">sizeof</span>(*a), cudaHostAllocDefault));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a, size * <span class="keyword">sizeof</span>(*dev_a)));</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(up)&#123;</span><br><span class="line">            HANDLE_ERROR(cudaMemcpy(dev_a, a, size * <span class="keyword">sizeof</span>(*dev_a), cudaMemcpyHostToDevice));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            HANDLE_ERROR(cudaMemcpy(a, dev_a, size * <span class="keyword">sizeof</span>(*dev_a), cudaMemcpyDeviceToHost));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(a));</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_a));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(stop));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> elapsedTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>cudaHostAlloc()分配的内存与malloc()分配的内存在使用方式是相同的，与malloc()不同之处在于最后一个参数cudaHostAllocDefault。最后一个参数的取值范围是一组标志，我们可以通过这些标志来修改cudaHostAlloc()的行为，并分配不同形式的固定主机内存。就目前而言，只需使用默认值。最后需要使用cudaFreeHost()来释放内存。</p><p>main()函数的代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SIZE (10 * 1024 * 1024)</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    <span class="type">float</span> MB = (<span class="type">float</span>)<span class="number">100</span> * SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>) / <span class="number">1024</span> / <span class="number">1024</span>;</span><br><span class="line">    elapsedTime = cuda_malloc_test(SIZE, <span class="literal">true</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time using cudaMalloc: %3.1fms\n&quot;</span>, elapsedTime);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\tMB/s during copy up: %3.1f\n&quot;</span>, MB / (elapsedTime / <span class="number">1000</span>));</span><br><span class="line">    <span class="comment">//要执行相反方向的性能，可以执行相同的调用，只需要将第二个参数指定为false</span></span><br><span class="line">    elapsedTime = cuda_malloc_test(SIZI, <span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time using cudaMalloc: %3.1f ms \n&quot;</span>, elapsedTime);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\tMB/s during copy down: %3.1f\n&quot;</span>, MB / (elapsedTime / <span class="number">1000</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//测试cudaHostAlloc()的性能</span></span><br><span class="line">    elapsedTime = cuda_host_malloc_test(SIZE, <span class="literal">true</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time using cudaHostMalloc: %3.1fms\n&quot;</span>, elapsedTime);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\tMB/s during copy up: %3.1f\n&quot;</span>, MB / (elapsedTime / <span class="number">1000</span>));</span><br><span class="line">    </span><br><span class="line">    elapsedTime = cuda_host_malloc_test(SIZI, <span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time using cudaHostMalloc: %3.1f ms \n&quot;</span>, elapsedTime);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\tMB/s during copy down: %3.1f\n&quot;</span>, MB / (elapsedTime / <span class="number">1000</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="CUDA流"><a href="#CUDA流" class="headerlink" title="CUDA流"></a>CUDA流</h2><p>之前介绍过cudaEventRecord()，并没有详细解释这个函数的第二个参数，这个第二个参数是用于指定插入事件的流(Stream)。CUDA流表示一个GPU操作队列，并且该队列中的操作将以指定的顺序执行。我们可以在流中添加一些操作，例如核函数启动、内存复制，以及时间的启动和结束等。你可以将每个流视为GPU上的一个任务，并且这些任务可以并行执行。我们将首先介绍如何使用流，然后介绍如何使用流来加速应用程序。</p><h3 id="使用单个CUDA流"><a href="#使用单个CUDA流" class="headerlink" title="使用单个CUDA流"></a>使用单个CUDA流</h3><p>仅当使用多个流时才能显现出流的真正威力。不过我们先用一个流来说明用法。下面的示例中，我们将计算a中三个值和b中三个值的平均值。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N (1024 * 1024)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> FULL_DATA_SIZE (N * 20)</span></span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">kernel</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span>&#123;</span><br><span class="line">    <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">if</span>(idx &lt; N)&#123;</span><br><span class="line">        <span class="type">int</span> idx1 = (idx + <span class="number">1</span>) % <span class="number">256</span>;</span><br><span class="line">        <span class="type">int</span> idx2 = (idx + <span class="number">2</span>) % <span class="number">256</span>;</span><br><span class="line">        <span class="type">float</span> as = (a[idx] + a[idx1] + a[idx2]) / <span class="number">3.0f</span>;</span><br><span class="line">        <span class="type">float</span> bs = (b[idx] + b[idx1] + b[idx2]) / <span class="number">3.0f</span>;</span><br><span class="line">        c[idx] = (as + bs) / <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">//选择一个一个支持设备重叠功能的设备。支持设备重叠功能的GPU能够在执行一个CUDA C核函数的同时，</span></span><br><span class="line">    <span class="comment">//还能在设备与主机之间执行复制操作。</span></span><br><span class="line">    cudaDeviceProp prop;</span><br><span class="line">    <span class="type">int</span> whichDevice;</span><br><span class="line">    HANDLE_ERROR(cudaGetDevice(&amp;whichDevice));</span><br><span class="line">    HANDLE_ERROR(cudaGetDeviceProperties(&amp;prop, whichDevice));</span><br><span class="line">    <span class="keyword">if</span>(!prop.deviceOverlap)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Device will not handle overlaps, so no speed up from streams\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//启动计时器</span></span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//初始化流</span></span><br><span class="line">    cudaStream_t stream;</span><br><span class="line">    HANDLE_ERROR(cudaStreamCreate(&amp;stream));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//数据分配操作</span></span><br><span class="line">    <span class="type">int</span> *host_a, *host_b, *host_c;</span><br><span class="line">    <span class="type">int</span> *dev_a, *dev_b, *dev_c;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_b, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_c, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//分配由流使用的页锁定内存</span></span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;host_a, FULL_DATA_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaHostAllocDefault));</span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;host_b, FULL_DATA_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaHostAllocDefault));</span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;host_c, FULL_DATA_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaHostAllocDefault));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; FULL_DATA_SIZE; i++)&#123;</span><br><span class="line">        host_a[i] = rand();</span><br><span class="line">        host_b[i] = rand();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>程序将使用主机上的固定内存。我们还会使用一种新的cudaMemcpy()函数，并且在这个新函数中需要页锁定主机内存。在分配完输入内存后，调用C的库函数rand()并用随机证书填充主机内存。</p><p>执行计算的方式是将两个输入缓冲区复制到GPU，启动核函数，然后将输出缓冲区复制回主机。不过，本示例做出了小的调整。首先，我们不将输入缓冲区整体都复制到GPU，而是将输入缓冲区划分为更小的块，并在每个块上执行一个包含三个步骤的过程。我们将一部分输入缓冲区复制到GPU，在这部分缓冲区上运行核函数，然后将输出缓冲区的这部分结果复制回主机。下面给出了一个需要这种方法的情形：GPU的内存远少于主机内存，由于整个缓冲区无法一次性填充到GPU，因此需要分块进行计算。执行“分块”计算的代码如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment">//在整体数据上循环，每个数据块的大小为N</span></span><br><span class="line">   <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; FULL_DATA_SIZE; i += N)&#123;</span><br><span class="line">       <span class="comment">//将锁定内存以异步的方式复制到设备上</span></span><br><span class="line">       HANDLE_ERROR(cudaMemcpyAsync(dev_a, host_a + i, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream));</span><br><span class="line">       HANDLE_ERROR(cudaMemcpyAsync(dev_b, host_b + i, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream));</span><br><span class="line">       kernel&lt;&lt;&lt;N / <span class="number">256</span>, <span class="number">256</span>, <span class="number">0</span>, stream&gt;&gt;&gt;(dev_a, dev_b, dev_c);</span><br><span class="line"></span><br><span class="line">       <span class="comment">//将数据从设备复制到锁定内存</span></span><br><span class="line">       HANDLE_ERROR(cudaMemcpyAsync(host_c + i, dev_c, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost. stream));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码使用cudaMemcpyAsync()在GPU与主机之间复制数据。cudaMemcpy()的行为类似于C库函数memcpy()，尤其是这个函数将以同步的方式进行。这意味着当函数返回时，复制操作就已经完成，并且在输出缓冲区中包含了复制进去的内容。异步函数的行为与同步函数相反，在调用cudaMemcpyAsync()时，只是放置一个请求，表示在流中执行一次内存复制操作，这个流时通过参数stream来指定的。当函数返回时，我们无法确保复制操作是否已经启动，更无法保证它是否已经结束。<strong>我们能够得到的保证是，复制操作肯定会将肯定会当下一个被放入流中的操作之前执行。</strong>任何传递给cudaMemcpyAsync()的主机内存指针都必须已经通过cudaHostAlloc()分配好内存。也就是，<strong>你只能以异步方式对页锁定内存进行复制操作。</strong></p><p>在核函数调用的尖括号中还可以带有一个流参数。此时核函数调用将是异步的。从技术上来说，当循环迭代完一次时，有可能不会启动任何内存复制或核函数执行。<strong>我们能够确保的是，第一次放入流中的复制操作将在第二次复制操作之前执行。此外，第二个复制操作将在核函数启动之前完成。而核函数将在第三次复制操作开始之前完成。</strong></p><p>当for循环结束时，在队列中应该包含了许多等待GPU执行的工作。如果想要确保GPU执行完了计算和内存复制等操作，那么就需要将GPU与主机同步。也就是说，主机在继续执行之前，要首先等待GPU执行完成。可以调用cudaStreamSynchronize()并制定想要等待的流。当程序执行到stream与主机同步之后的代码时，所有的计算和复制操作都已经完成，因此停止计时器，收集性能数据，并释放输入缓冲区和输出缓冲区。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">//将计算结果从页锁定内存复制到主机内存</span></span><br><span class="line">    HANDLE_ERROR(cudaStreamSynchronize(stream));</span><br><span class="line"></span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time taken: 3.1%f ms\n&quot;</span>, elapsedTime);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放流和内存</span></span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(host_a));</span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(host_b));</span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(host_c));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_a));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_b));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_c));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//销毁对GPU操作进行排队的流</span></span><br><span class="line">    HANDLE_ERROR(cudaStreamDestroy(stream));</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用多个CUDA流"><a href="#使用多个CUDA流" class="headerlink" title="使用多个CUDA流"></a>使用多个CUDA流</h3><p>我们将上面的示例改为使用两个不同的流。我们将实现：在第0个流执行核函数的同时，第1个流将输入缓冲区复制到GPU。然后在第0个流将计算结果复制回主机的同时，第1个流将执行核函数。接着，第1个流将计算结果复制回主机，同时第0个流开始在下一块数据上执行核函数。假设内存复制操作和核函数执行的事件大致相同，那么应用程序的执行时间线将如图下所示（后续图片中函数调用cudaMemcpyAsync()被简写为复制）：</p><p><img src="/imgs/CUDA_7_1.png" alt="CUDA_7_1"></p><p>核函数的代码保持不变。与使用单个流的版本一样，我们将判断设备是否支持计算与内存复制操作的重叠。如果设备支持重叠，那么就像前面一样创建CUDA事件并对应用程序计时。创建两个流的方式与之前代码中创建单个流的方式是一样的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N (1024 * 1024)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> FULL_DATA_SIZE (N * 20)</span></span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">kernel</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span>&#123;</span><br><span class="line">    <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">if</span>(idx &lt; N)&#123;</span><br><span class="line">        <span class="type">int</span> idx1 = (idx + <span class="number">1</span>) % <span class="number">256</span>;</span><br><span class="line">        <span class="type">int</span> idx2 = (idx + <span class="number">2</span>) % <span class="number">256</span>;</span><br><span class="line">        <span class="type">float</span> as = (a[idx] + a[idx1] + a[idx2]) / <span class="number">3.0f</span>;</span><br><span class="line">        <span class="type">float</span> bs = (b[idx] + b[idx1] + b[idx2]) / <span class="number">3.0f</span>;</span><br><span class="line">        c[idx] = (as + bs) / <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    cudaDeviceProp prop;</span><br><span class="line">    <span class="type">int</span> whichDevice;</span><br><span class="line">    HANDLE_ERROR(cudaGetDevice(&amp;whichDevice));</span><br><span class="line">    HANDLE_ERROR(cudaGetDeviceProperties(&amp;prop, whichDevice));</span><br><span class="line">    <span class="keyword">if</span>(!prop.deviceOverlap)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Device will not handle overlaps, so no speed up from streams\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//启动计时器</span></span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//初始化流</span></span><br><span class="line">    cudaStream_t stream0, stream1;</span><br><span class="line">    HANDLE_ERROR(cudaStreamCreate(&amp;stream0));</span><br><span class="line">    HANDLE_ERROR(cudaStreamCreate(&amp;stream1));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//数据分配操作</span></span><br><span class="line">    <span class="type">int</span> *host_a, *host_b, *host_c;</span><br><span class="line">    <span class="type">int</span> *dev_a0, *dev_b0, *dev_c0; <span class="comment">//为第0个流分配的GPU内存</span></span><br><span class="line">    <span class="type">int</span> *dev_a1, *dev_b1, *dev_c1; <span class="comment">//为第1个流分配的GPU内存</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a0, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_b0, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_c0, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a1, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_b1, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_c1, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//分配由流使用的页锁定内存</span></span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;host_a, FULL_DATA_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaHostAllocDefault));</span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;host_b, FULL_DATA_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaHostAllocDefault));</span><br><span class="line">    HANDLE_ERROR(cudaHostAlloc((<span class="type">void</span>**)&amp;host_c, FULL_DATA_SIZE * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaHostAllocDefault));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; FULL_DATA_SIZE; i++)&#123;</span><br><span class="line">        host_a[i] = rand();</span><br><span class="line">        host_b[i] = rand();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>之后，程序在输入数据块上循环。然而，由于现在使用了两个流，因此在for()循环的迭代中需要处理的数据量也是原来的两倍。在stream()中，我们首先将a和b的异步复制操作放入GPU的队列，然后将一个核函数执行放入队列，接下来再将一个复制回c的操作放入队列：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在整体数据上循环，每个数据块的大小为N</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; FULL_DATA_SIZE; i += N * <span class="number">2</span>)&#123;</span><br><span class="line">    <span class="comment">//将锁定内存以异步方式复制到设备上</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(dev_a0, host_a + i, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream0));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(dev_b0, host_b + i, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream0));</span><br><span class="line">    kernel&lt;&lt;&lt;N / <span class="number">256</span>, <span class="number">256</span>, <span class="number">0</span>, stream0&gt;&gt;&gt;(dev_a0, dev_b0, dev_c0);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数据从设备复制回锁定内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(host_c + i, dev_c0, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost, stream0));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在将这些操作放入stream0队列后，再把下一个数据块上的相同操作放入stream1的队列中</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//将锁定内存以异步方式复制到设备上</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(dev_a1, host_a + i + N, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream1));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(dev_b1, host_b + i + N, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream1));</span><br><span class="line">    kernel&lt;&lt;&lt;N / <span class="number">256</span>, <span class="number">256</span>, <span class="number">0</span>, stream1&gt;&gt;&gt;(dev_a1, dev_b1, dev_c1);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数据从设备复制回锁定内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(host_c + i + N, dev_c1, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost, stream0));</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，在for循环的迭代过程中，将交替地把每个数据块放入这两个流的队列，直到所有待处理的输入数据都被放入队列。在结束了for循环后，在停止应用程序的计时器之前，首先将GPU与GPU进行同步，由于使用了两个流，因此要对二者都进行同步。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">HANDLE_ERROR(cudaStreamSynchronize(stream0));</span><br><span class="line">HANDLE_ERROR(cudaStreamSynchronize(stream1));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time taken: 3.1%f ms\n&quot;</span>, elapsedTime);</span><br><span class="line"></span><br><span class="line"><span class="comment">//释放流和内存</span></span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(host_a));</span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(host_b));</span><br><span class="line">    HANDLE_ERROR(cudaFreeHost(host_c));</span><br><span class="line"><span class="comment">//销毁两个流，释放两倍的GPU内存</span></span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_a0));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_b0));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_c0));</span><br><span class="line">HANDLE_ERROR(cudaFree(dev_a1));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_b1));</span><br><span class="line">    HANDLE_ERROR(cudaFree(dev_c1));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//销毁对GPU操作进行排队的流</span></span><br><span class="line">    HANDLE_ERROR(cudaStreamDestroy(stream0));</span><br><span class="line">HANDLE_ERROR(cudaStreamDestroy(stream1));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="GPU的工作调度机制"><a href="#GPU的工作调度机制" class="headerlink" title="GPU的工作调度机制"></a>GPU的工作调度机制</h3><p>我们可以将流视为有序的操作序列，其中既包含内存复制操作，又包含核函数调用。下图将展示任务调度情形。</p><p><img src="/imgs/CUDA_7_2.png" alt="CUDA_7_2"></p><p>从图中得到，第0个流对A的内存复制需要在对B的内存复制之前完成，而对B的复制又要在核函数A启动之前完成。然而，一旦这些操作放入到硬件的内存复制引擎和核函数执行引擎的队列中时，这些依赖性将丢失，因此CUDA驱动程序需要确保硬件的执行单元不破坏流内部的依赖性。</p><p>从之前的代码中可以得知，应用程序基本上是对a调用一次cudaMemcpyAsync()，对b调用一次cudaMemcpyAsync()，然后再是执行核函数以及调用cudaMemcpyAsync()将c复制回主机。应用程序首先将第0个流的所有操作放入队列，然后是第1个流的所有操作。CUDA驱动程序负责按照这些操作的顺序把他们调度到硬件上执行，这就维持了流内部的依赖性。下图体现了这些依赖性，其中从复制操作到核函数的箭头表示，复制操作要等核函数执行完成之后才能开始。</p><p><img src="/imgs/CUDA_7_3.png" alt="CUDA_7_3"></p><p>假定理解了GPU的工作调度远离后，我们可以得到关于这些操作在硬件上执行的时间线，如下图所示：</p><p><img src="/imgs/CUDA_7_4.png" alt="CUDA_7_4"></p><p>由于第0个流中将c复制回主机的操作要等待核函数执行完成，因此第1个流中将a和b复制到GPU的操作虽然是完全独立的，但却被阻塞了，这是因为GPU引擎是按照指定的顺序来执行工作。这种情况很好地说明了为什么在程序中使用了两个流却无法获得加速的窘境。这个问题的直接原因是我们没有意识到硬件的工作方式与CUDA流编程模型的方式是不同的。</p><h3 id="高效地使用多个CUDA流"><a href="#高效地使用多个CUDA流" class="headerlink" title="高效地使用多个CUDA流"></a>高效地使用多个CUDA流</h3><p>从上面的说明可以得出，如果同时调度某个流的所有操作，那么很容易在无意中阻塞另一个流的复制操作或者核函数执行。要解决这个问题，在将操作放入流的队列时应采用宽度优先的方式，而非深度优先的方式。<strong>也就是说不是首先添加第0个流的所有四个操作（即a的复制、b的复制、核函数以及c的复制），然后不再添加第1个流的所有四个操作，而是将这两个流之间的操作交叉添加。</strong></p><p>首先，将a的复制操作添加到第0个流，然后将a的复制操作添加到第1个流。接着，将b的复制操作添加到第0个流，再将b的复制操作添加到第1个流。接下来，将核函数调用添加到第0个流，再将相同的操作添加到第1个流中。最后，将c的复制操作添加到第0个流中，然后将相同的操作添加到第1个流中。</p><p>下面是实际的代码。我们的修改仅限于for循环中的两个流的处理，采用宽度优先方式将操作分配到两个流的代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; FULL_DATA_SIZE; i += N * <span class="number">2</span>)&#123;</span><br><span class="line">    <span class="comment">//将复制a的操作放入stream0和stream1的队列</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(dev_a0, host_a + i, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream0));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(dev_a1, host_a + i + N, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream1));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将复制b的操作放入stream0和stream1的队列</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(dev_b0, host_b + i, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream0));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(dev_b1, host_b + i + N, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice, stream1));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将核函数的执行放入stream0和stream1的队列中</span></span><br><span class="line">    kernel&lt;&lt;&lt;N / <span class="number">256</span>, <span class="number">256</span>, <span class="number">0</span>, stream0&gt;&gt;&gt;(dev_a0, dev_b0, dev_c0);</span><br><span class="line">    kernel&lt;&lt;&lt;N / <span class="number">256</span>, <span class="number">256</span>, <span class="number">0</span>, stream1&gt;&gt;&gt;(dev_a1, dev_b1, dev_c1);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将复制c的操作放入stream0和stream1的队列</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(host_c + i, dev_c0, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost, stream0));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpyAsync(host_c + i + N, dev_c1, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost, stream1));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时，新的执行时间线将如下图所示：</p><p><img src="/imgs/CUDA_7_5.png" alt="CUDA_7_5"></p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/02/28/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%83/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(六)</title>
      <link>http://example.com/2024/02/27/CUDA%E5%AD%A6%E4%B9%A0-%E5%85%AD/</link>
      <guid>http://example.com/2024/02/27/CUDA%E5%AD%A6%E4%B9%A0-%E5%85%AD/</guid>
      <pubDate>Tue, 27 Feb 2024 08:11:02 GMT</pubDate>
      
      <description>&lt;p&gt;在某些情况中，对于单线程应用程序来说非常简单的任务，在大规模并行架构上实现时会变成一个复杂的问题。在本章中，我们将举例其中一些情况，并在这些情况中安全地完成传统单线程应用程序中的简单任务。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>在某些情况中，对于单线程应用程序来说非常简单的任务，在大规模并行架构上实现时会变成一个复杂的问题。在本章中，我们将举例其中一些情况，并在这些情况中安全地完成传统单线程应用程序中的简单任务。</p><span id="more"></span><h2 id="原子操作简介"><a href="#原子操作简介" class="headerlink" title="原子操作简介"></a>原子操作简介</h2><p>在编写传统的单线程应用程序时，程序员通常不需要使用原子操作。下面会介绍一下原子操作是什么，以及为什么在多线程程序中需要使用它们。我们先分析C或者C++的递增运算符：</p><p>x++;</p><p>在这个操作中包含了三个步骤：</p><ol><li>读取x中的值。</li><li>将步骤1中读到的值增加1。</li><li>将递增后的结果写回到x。</li></ol><p>有时候，这个过程也称为读取-修改-写入操作。</p><p>当两个线程都需要对x的值进行递增时，假设x的初始值为7，理想情况下，两个线程按顺序对x进行递增，第一个线程完成三个步骤后第二个线程紧接着完成三个步骤，最后得到的结果是9。但是，实际情况下会出现两个线程的操作彼此交叉进行，这种情况下得到的结果将小于9(比如两个线程同时读取x&#x3D;7，计算完后写入，那样的话x最后会等于8)。</p><p>因此，我们需要通过某种方式一次性地执行完读取-修改-写入这三个操作，并在执行过程中不会被其他线程中断。<strong>由于这些操作的执行过程不能分解为更小的部分，因此我们将满足这种条件限制的操作称为原子操作。</strong></p><h2 id="计算直方图"><a href="#计算直方图" class="headerlink" title="计算直方图"></a>计算直方图</h2><p>本章将通过给出计算直方图的例子来介绍如何进行原子性计算。</p><h3 id="在CPU上计算直方图"><a href="#在CPU上计算直方图" class="headerlink" title="在CPU上计算直方图"></a>在CPU上计算直方图</h3><p>某个数据的直方图表示每个元素出现的频率。在示例中，这个数据将是随机生成的字节流。我们可以通过工具函数big_random_block()来生成这个随机的字节流。在应用程序中将生成100MB的随机数据。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SIZE (100 * 1024 * 1024)</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *buffer = (<span class="type">unsigned</span> <span class="type">char</span>*)big_random_block(SIZE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于每个随机字节（8比特）都有256个不同的可能取值（从0x00到0xFF），因此在直方图中需要包含256个元素，每个元素记录相应的值在数据流中的出现次数。我们创建了一个包含256个元素的数组，并将所有元素的值初始化为0。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> histo[<span class="number">256</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">256</span>; i++)&#123;</span><br><span class="line">    histo[i] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来需要计算每个值在buffer[]数据中的出现频率。算法思想是，每当在数组buffer[]中出现某个值z时，就递增直方图数组中索引为z的元素，这样就能计算出值z的出现次数。如果当前看到的值为buffer[i]，那么将递增数组中索引等于buffer[i]的元素。由于元素buffer[i]位于histo[buffer[i]]，我们只需一行代码就可以递增相应的计数器。在一个for循环中对buffer[]中的每个元素执行这个操作：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; SIZE; i++)&#123;</span><br><span class="line">    histo[buffer[i]]++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来将验证直方图的所有元素相加起来是否等于正确的值。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> histoCount = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">256</span>; i++)&#123;</span><br><span class="line">    histoCount += histo[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Histogram Sum: %ld\n&quot;</span>, histoCount);</span><br><span class="line"></span><br><span class="line"><span class="built_in">free</span>(buffer);</span><br></pre></td></tr></table></figure><h3 id="在GPU上计算直方图"><a href="#在GPU上计算直方图" class="headerlink" title="在GPU上计算直方图"></a>在GPU上计算直方图</h3><p>以下时计算直方图的GPU版本</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span>* buffer = (<span class="type">unsigned</span> <span class="type">char</span>*)big_random_block(SIZE);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//初始化计时事件</span></span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上为文件的数据分配内存</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *dev_buffer;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> *dev_histo;</span><br><span class="line">    HANDLE_ERROR(cudaMallc((<span class="type">void</span>**)&amp;dev_buffer, SIZE));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_buffer, buffer, SIZE, cudaMemcpyHostToDevice));</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_histo, <span class="number">256</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMemset(dev_histo, <span class="number">0</span>, <span class="number">256</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> histo[<span class="number">256</span>];</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(histo, dev_histo, <span class="number">256</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//得到停止事件并显示计时结果</span></span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time to generate: %3.1f ms\n&quot;</span>, elapsedTime);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//下面是验证直方图的总和是否等于正确的值，因为是在CPU上运行，并不需要对此进行计时</span></span><br><span class="line">    <span class="type">long</span> histoCount = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">256</span>; i++)&#123;</span><br><span class="line">        histoCount += histo[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Histogram Sum: %ld\n&quot;</span>, histoCount);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//验证GPU与CPU的搭配的是相同的计数值</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; SIZE; i++)&#123;</span><br><span class="line">        histo[buffer[i]]--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">256</span>; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(histo[i] != <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Failure at %d!\n&quot;</span>, i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(stop));</span><br><span class="line">    cudaFree(dev_histo);</span><br><span class="line">    cudaFree(dev_buffer);</span><br><span class="line">    <span class="built_in">free</span>(buffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>cudaMemset()与C的memset()是相似的，不同之处在于cudaMemset()将返回一个错误码，将高速调用者在设置GPU内存时发生的错误。</p><p>接下来会介绍GPU上计算直方图的代码。计算直方图的核函数需要的参数包括：</p><ul><li>一个指向输入数组的指针</li><li>输入数组的长度</li><li>一个指向输出直方图的指针</li></ul><p>核函数执行的第一个计算就是计算输入数据数组中的偏移。每个线程的起始偏移都是0到线程数量减1之间的某个值，然后，对偏移的增量为已启动线程的总数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SIZE (100 * 1024 * 1024)</span></span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">histo_kernel</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> *buffer, <span class="type">long</span> size, <span class="type">unsigned</span> <span class="type">int</span> *histo)</span>&#123;</span><br><span class="line">    <span class="type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//当每个线程知道它的起始偏移i以及递增的数量，这段代码将遍历输入数组，并递增直方图中相应元素的值</span></span><br><span class="line">    <span class="keyword">while</span>(i &lt; size)&#123;</span><br><span class="line">        atomicAdd(&amp;(histo[buffer[i]]), <span class="number">1</span>);</span><br><span class="line">        i += stride;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数调用atomicAdd(addr, y)将生成一个原子的操作序列，这个操作序列包括读取地址addr处的值，将y增加到这个值，以及将结果保存回地址addr。底层硬件将确保当执行这些操作时，其他任何线程都不会读取或写入地址addr上的值。</p><p>然而，原子操作回导致性能降低，但是解决问题的方法有时会需要更多而非更少的原子操作。<strong>这里的主要问题并非在于使用了过多的原子操作，而是有数千个线程在少量的内存地址上发生竞争。</strong>要解决这个问题，我们需要将直方图计算分为两个阶段。</p><ul><li>第一个阶段，每个并行线程块将计算它所处理数据的直方图。每个线程块在执行这个操作时都是相互独立的，因此可以在共享内存中计算这些直方图，这将避免每次将写入操作从芯片发送到DRAM。但是这种方式仍然需要原子操作，因为线程块中的多个线程之间仍然会处理相同值的数据元素。<strong>不过，现在只有256个线程在256个地址上发生竞争，这将极大地减少在使用全局内存时在数千个线程之间发生竞争的情况。</strong>我们将使用共享内存缓冲区temp[]而不是全局内存缓冲区histo[]，而且需要随后调用__syncthreads()来确保提交最后的写入操作。</li><li>第二个阶段则是将每个线程块的临时直方图合并到全局缓冲区histo[]中。由于我们使用了256个线程，并且直方图中包含了256个元素，因此每个线程将自动把它计算得到的元素只增加到最终直方图的元素上（如果线程数量不等于元素数量，那么这个阶段将更为复杂）。我们并不保证线程块将按照何种顺序将各自的值相加到最终直方图中，但由于整数加法时可交换的，无论哪种顺序都会得到相同的结果。</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">histo_kernel</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span>* buffer, <span class="type">long</span> size, <span class="type">unsigned</span> <span class="type">int</span> *histo)</span>&#123;</span><br><span class="line">    __shared__ <span class="type">unsigned</span> <span class="type">int</span> temp[<span class="number">256</span>];</span><br><span class="line">    temp[threadIdx.x] = <span class="number">0</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">    <span class="keyword">while</span>(i &lt; size)&#123;</span><br><span class="line">        stomicAdd(&amp;temp[buffer[i]], <span class="number">1</span>);</span><br><span class="line">        i += offset;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    atomicAdd(*(histo[threadIdx.x]), temp[threadIdx.x]);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/02/27/CUDA%E5%AD%A6%E4%B9%A0-%E5%85%AD/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(五)</title>
      <link>http://example.com/2024/02/24/CUDA%E5%AD%A6%E4%B9%A0-%E4%BA%94/</link>
      <guid>http://example.com/2024/02/24/CUDA%E5%AD%A6%E4%B9%A0-%E4%BA%94/</guid>
      <pubDate>Sat, 24 Feb 2024 08:06:05 GMT</pubDate>
      
      <description>&lt;p&gt;本章将学习如何分配和使用纹理内存(texture memory)。和常量内存一样，纹理内存是另一种类型的只读内存，在特定的访问模式中，纹理内存同样能够提升性能并减少内存流量。虽然纹理内存最初是针对传统的图形处理应用程序而设计的，但在某些GPU计算应用程序中同样非常有用。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本章将学习如何分配和使用纹理内存(texture memory)。和常量内存一样，纹理内存是另一种类型的只读内存，在特定的访问模式中，纹理内存同样能够提升性能并减少内存流量。虽然纹理内存最初是针对传统的图形处理应用程序而设计的，但在某些GPU计算应用程序中同样非常有用。</p><span id="more"></span><p>与常量内存相似的是，纹理内存同样缓存在芯片上，因此在某些情况中，它能够减少对内存请求并提供更高效的内存带宽。纹理缓存是专门为那些在内存访问模式中存在大量空间局部性(spatial locality)的图形应用程序而设计的。在某个计算应用程序中，这意味着一个线程读取的位置可能与邻近线程读取的位置“非常接近”。</p><h2 id="热传导模拟"><a href="#热传导模拟" class="headerlink" title="热传导模拟"></a>热传导模拟</h2><p>本章用一个简单的热传导模拟的模型来介绍如何使用纹理内存。</p><h3 id="简单的传热模型"><a href="#简单的传热模型" class="headerlink" title="简单的传热模型"></a>简单的传热模型</h3><p>我们构造一个简单的二维热传导模拟。首先假设有一个矩形房间，将其分成一个格网，每个格网中随机散步一些“热源”，他们有着不同的温度。</p><p><img src="/imgs/CUDA_5_1.png" alt="CUDA_5_1"></p><p>在给定了矩形格网以及热源分布后，我们可以计算格网中每个单元格的温度随时间的变化情况。为了简单，热源单元本身的温度将保持不变。在时间递进的每个步骤中，我们假设热量在某个单元及其邻接单元之间“流动”。如果某个单元的临界单元的温度更高，那么热量将从邻接单元传导到该单元，相反地，如果某个单元的温度比邻接单元的温度高，那么它将变冷。</p><p>在热传导模型中，我们对单元中新温度的计算方法为，将单元与邻接单元的温差相加起来，然后加上原有温度。<br>$$<br>T_{NEW} &#x3D; T_{OLD} + \sum_{NEIGHBOURS}k(T_{NEIGHBORS} - T_{OLD})<br>$$<br>在上面的计算单元温度的等式中，常量k表示模拟过程中热量的流动速率，k值越大，表示系统会更快地达到稳定温度，而k值越小，则温度梯度将存在更长时间。由于我们只考虑4个邻接单元(上、下、左、右)并且等式中的k和$$T_{OLD}$$都是常数，因此把上述公式展开表示为:<br>$$<br>T_{NEW} &#x3D; T_{OLD} + k(T_{TOP} + T_{BOTTOM} + T_{LEFT} + T_{RIGHT} - 4T_{OLD})<br>$$</p><h3 id="温度更新的计算"><a href="#温度更新的计算" class="headerlink" title="温度更新的计算"></a>温度更新的计算</h3><p>以下是更新流程的基本介绍:</p><ol><li>给定一个包含初始输入温度的格网，将其中作为热源的单元温度值复制到格网相应的单元中来覆盖这些单元之前计算出来的温度，确保“加热单元将保持恒温”的条件。这个复制操作在copy_const_kernel()中执行。</li><li>给定一个输入温度格网，根据新的公式计算出输出温度格网。这个更新操作在blend_kernel()中执行。</li><li>将输入温度格网和输出温度格网交换，为下一个步骤的计算做好准备。当模拟下一个时间步时，在步骤2中计算得到的输出温度格网将成为步骤1中的输入温度格网。</li></ol><p>下面是两个函数的具体实现:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">copy_const_kernel</span><span class="params">(<span class="type">float</span> *iptr, <span class="type">const</span> <span class="type">float</span> *cptr)</span>&#123;</span><br><span class="line">    <span class="comment">//将threadIdx/BlockIdx映射到像素位置</span></span><br><span class="line">    <span class="type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(cptr[offset] != <span class="number">0</span>)&#123;</span><br><span class="line">        iptr[offset] = cptr[offset];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//为了执行更新操作，可以在模拟过程中让每个线程都负责计算一个单元。</span></span><br><span class="line"><span class="comment">//每个线程都将读取对应单元及其邻接单元的温度值，执行更新运算，然后计算得到新值来更新温度。</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">blend_kernel</span><span class="params">(<span class="type">float</span> *outSrc, <span class="type">const</span> <span class="type">float</span> *inSrc)</span>&#123;</span><br><span class="line">    <span class="comment">//将threadIdx/BlockIdx映射到像素位置</span></span><br><span class="line">    <span class="type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> left = offset - <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> right = offset + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span>(x == <span class="number">0</span>) left++;</span><br><span class="line">    <span class="keyword">if</span>(x == DIM - <span class="number">1</span>) right--;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> top = offset - DIM;</span><br><span class="line">    <span class="type">int</span> bottom = offset + DIM;</span><br><span class="line">    <span class="keyword">if</span>(y == <span class="number">0</span>) bottom += DIM;</span><br><span class="line">    <span class="keyword">if</span>(y == DIM - <span class="number">1</span>) top -= DIM;</span><br><span class="line">    </span><br><span class="line">    outSrc[offset] = inSrc[offset] + SPEED * (inSrc[top] + inSrc[bottom] + inSrc[left] + inSrc[right] - inSrc[offset] * <span class="number">4</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="模拟过程动态演示"><a href="#模拟过程动态演示" class="headerlink" title="模拟过程动态演示"></a>模拟过程动态演示</h3><p>剩下的代码主要是设置好单元，然后显示热量的动画输出</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cpu_anim.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM 1024</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PI 3.1415926535897932f</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX_TEMP 1.0f</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MIN_TEMP 0.0001f</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SPEED 0.25f</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//更新函数中需要的全局变量</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">DataBlock</span>&#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *output_bitmap;</span><br><span class="line">    <span class="type">float</span> *dev_inSrc;</span><br><span class="line">    <span class="type">float</span> *dev_outSrc;</span><br><span class="line">    <span class="type">float</span> *dev_constSrc;</span><br><span class="line">    CPUAnimBitmap *bitmap;</span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">float</span> totalTime;</span><br><span class="line">    <span class="type">float</span> frames;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">anim_gpu</span><span class="params">(DataBlock *d, <span class="type">int</span> ticks)</span>&#123;</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(d-&gt;start, <span class="number">0</span>));</span><br><span class="line">    dim3 <span class="title function_">blocks</span><span class="params">(DIM / <span class="number">16</span>, DIM / <span class="number">16</span>)</span>;</span><br><span class="line">    dim3 <span class="title function_">threads</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span>;</span><br><span class="line">    CPUAnimBitmap *bitmap = d-&gt;bitmap;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">90</span>; <span class="number">0</span>++)&#123;</span><br><span class="line">        copy_const_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d-&gt;dev_inSrc, d-&gt;dev_constSrc);</span><br><span class="line">        blend_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d-&gt;dev_inSrc, d-&gt;dev_constSrc);</span><br><span class="line">        swap(d-&gt;dev_inSrc, d-&gt;dev_outSrc);</span><br><span class="line">    &#125;</span><br><span class="line">    float_to_color&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d-&gt;output_bitmap, d-&gt;dev_inSrc);</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(bitmap-&gt;get_ptr(), d-&gt;output_bitmap, bitmap-&gt;image_size(), cudaMemcpyDeviceToHost));</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(d-&gt;stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(d-&gt;stop));</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, d-&gt;start, d-&gt;stop));</span><br><span class="line">    </span><br><span class="line">    d-&gt;totalTime += elapsedTime;</span><br><span class="line">    ++d-&gt;frames;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Averaged Time per frame: $3.1f ms \n&quot;</span>, d-&gt;totalTime / d-&gt;frames);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">anim_exit</span><span class="params">(DataBlock *d)</span>&#123;</span><br><span class="line">    cudaFree(d-&gt;dev_inSrc);</span><br><span class="line">    cudaFree(d-&gt;dev_outSrc);</span><br><span class="line">    cudaFree(d-&gt;dev_constSrc);</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(d-&gt;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(d-&gt;stop));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    DataBlock data;</span><br><span class="line">    CPUAnimBitmap <span class="title function_">bitmap</span><span class="params">(DIM, DIM, &amp;data)</span>;</span><br><span class="line">    data.bitmap = &amp;bitmap;</span><br><span class="line">    data.totalTime = <span class="number">0</span>;</span><br><span class="line">    data.frames = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;data.start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;data.stop));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.output_bitmap, bitmap.image_size()));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//假设float类型的大小为4个字符(即rgba)</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_inSrc, bitmap.image_size()));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_outSrc, bitmap.image_size()));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_constSrc, bitmap.image_size()));</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *temp = (<span class="type">float</span>*)<span class="built_in">malloc</span>(bitmap.image_size());</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; DIM*DIM; i++)&#123;</span><br><span class="line">        temp[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> x = i % DIM;</span><br><span class="line">        <span class="type">int</span> y =i / DIM;</span><br><span class="line">        <span class="keyword">if</span>((x &gt; <span class="number">300</span>) &amp;&amp; (x &lt; <span class="number">600</span>) &amp;&amp; (y &gt; <span class="number">310</span>) &amp;&amp; (y &lt; <span class="number">601</span>))&#123;</span><br><span class="line">            temp[i] = MAX_TEMP;</span><br><span class="line">        &#125;</span><br><span class="line">        temp[DIM * <span class="number">100</span> + <span class="number">100</span>] = (MAX_TEMP + MIN_TEMP) / <span class="number">2</span>;</span><br><span class="line">        temp[DIM * <span class="number">700</span> + <span class="number">100</span>] = MIN_TEMP;</span><br><span class="line">        temp[DIM * <span class="number">300</span> + <span class="number">300</span>] = MIN_TEMP;</span><br><span class="line">        temp[DIM * <span class="number">200</span> + <span class="number">700</span>] = MIN_TEMP;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> y = <span class="number">800</span>; y &lt; <span class="number">900</span>; y++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> x = <span class="number">400</span>; x &lt; <span class="number">500</span>; x++)&#123;</span><br><span class="line">                temp[x * y * DIM] = MIN_TEMP;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        HANDLE_ERROR(cudaMemcpy(data.dev_constSrc, temp, bitmap.image_size(), cudaMemcpyHostToDevice));</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">free</span>(temp);</span><br><span class="line">        </span><br><span class="line">        bitmap.anim_and_exit((<span class="type">void</span> (*) (<span class="type">void</span>*, <span class="type">int</span>)) anim_gpu, (<span class="type">void</span> (*) (<span class="type">void</span>*)) anim_exit);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用纹理内存"><a href="#使用纹理内存" class="headerlink" title="使用纹理内存"></a>使用纹理内存</h3><p>如果要使用纹理内存，首先要将输入的数据声明为texture类型的引用。我们使用浮点类型纹理的引用，因为温度数值是浮点类型。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这些变量将位于GPU上</span></span><br><span class="line">texture&lt;<span class="type">float</span>&gt; texConstSrc;</span><br><span class="line">texture&lt;<span class="type">float</span>&gt; textIn;</span><br><span class="line">texture&lt;<span class="type">float</span>&gt; textOut;</span><br></pre></td></tr></table></figure><p>下一个需要注意的问题是，在为这三个缓冲区分配了GPU内存后，需要通过cudaBindTexture()将这些变量绑定到内存缓冲区。这相当于告诉CUDA运行时两件事情：</p><ul><li>我们希望将制定的缓冲区作为纹理来使用。</li><li>我们希望将纹理引用作为纹理的“名字”。</li></ul><p>在热传导模拟中分配了这三个内存后，需要将这三个内存绑定到之前声明的纹理引用(texConstSrc, textIn, textOut)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_inSrc, imageSize));</span><br><span class="line">HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_outSrc, imageSize));</span><br><span class="line">HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_constSrc, imageSize));</span><br><span class="line"></span><br><span class="line">HANDLE_ERROR(cudaBindTexture(<span class="literal">NULL</span>, textConstSrc, data.dev_constSrc, imageSize));</span><br><span class="line">HANDLE_ERROR(cudaBindTexture(<span class="literal">NULL</span>, textIn, data.dev_inSrc, imageSize));</span><br><span class="line">HANDLE_ERROR(cudaBindTexture(<span class="literal">NULL</span>, textOut, data.dev_outStc, imageSize));</span><br></pre></td></tr></table></figure><p>此时，纹理变量已经设置好，可以启动核函数。然而，当读取核函数中的纹理时，需要通过特殊的函数来告诉GPU将读取请求转发到纹理内存而不是标准的全局内存。因此，当读取内存时不再使用方括号从缓冲区读取，而是将blend_kernel()函数内修改为使用tex1Dfetch()。</p><p>tex1Dfetch()实际上是一个编译器内置函数。由于纹理引用必须声明为文件作用域内的全局变量，因此我们不再将输入缓冲区和输出缓冲区作为参数传递给blend_kernel()，因为编译器需要在编译时知道text1Dfetch()应该对哪些纹理采样。我们需要将一个布尔标志dstOut传递给blend_kernel()，这个标志会告诉我们使用那个缓冲区作为输入，以及哪个缓冲区作为输出。以下是对blend_kernel()的修改。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">blend_kernel</span><span class="params">(<span class="type">float</span> *dst, <span class="type">bool</span> dstOut)</span>&#123;</span><br><span class="line">    <span class="comment">//将threadIdx/BlockIdx映射到像素位置</span></span><br><span class="line">    <span class="type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> left = offset - <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> right = offset + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span>(x == <span class="number">0</span>) left++;</span><br><span class="line">    <span class="keyword">if</span>(x == DIM - <span class="number">1</span>) right--;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> top = offset - DIM;</span><br><span class="line">    <span class="type">int</span> bottom = offset + DIM;</span><br><span class="line">    <span class="keyword">if</span>(y == <span class="number">0</span>) bottom += DIM;</span><br><span class="line">    <span class="keyword">if</span>(y == DIM - <span class="number">1</span>) top -= DIM;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//替换该行代码</span></span><br><span class="line">    <span class="comment">// outSrc[offset] = inSrc[offset] + SPEED * (inSrc[top] + inSrc[bottom] + inSrc[left] + inSrc[right] - inSrc[offset] * 4);</span></span><br><span class="line">    <span class="type">float</span> t, l, c, r, b;</span><br><span class="line">    <span class="keyword">if</span>(dstOut)&#123;</span><br><span class="line">        t = text1Dfetch(textIn, top);</span><br><span class="line">        l = text1Dfetch(textIn, left);</span><br><span class="line">        c = text1Dfetch(textIn, offset);</span><br><span class="line">        r = text1Dfetch(textIn, right);</span><br><span class="line">        b = text1Dfetch(textIn, bottom);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        t = text1Dfetch(textOut, top);</span><br><span class="line">        l = text1Dfetch(textOut, left);</span><br><span class="line">        c = text1Dfetch(textOut, offset);</span><br><span class="line">        r = text1Dfetch(textOut, right);</span><br><span class="line">        b = text1Dfetch(textOut, bottom);</span><br><span class="line">    &#125;</span><br><span class="line">    dst[offset] = c + SPEED * (t + b + r + l - <span class="number">4</span> * c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于核函数copy_const_kernel()将读取包含热源位置和温度的缓冲区，因此同样需要修改为从纹理内存而不是从全局内存中读取：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">copy_const_kernel</span><span class="params">(<span class="type">float</span> *iptr)</span>&#123;</span><br><span class="line">    <span class="comment">//将threadIdx/BlockIdx映射到像素位置</span></span><br><span class="line">    <span class="type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> c = text1Dfetch(textConstSrc, offset);</span><br><span class="line">    <span class="keyword">if</span>(c != <span class="number">0</span>)&#123;</span><br><span class="line">        iptr[offset] = c;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于blend_kernel()的函数原型被修改为接收一个标志，并且这个标志表示在输入缓冲区与输出缓冲区之间的切换，因此需要对anim_gpu()函数进行相应的修改。现在，不是交换缓冲区，而是在每组调用之后通过设置dstOut &#x3D; !dstOut来进行切换：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">anim_gpu</span><span class="params">(DataBlock *d, <span class="type">int</span> ticks)</span>&#123;</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(d-&gt;start, <span class="number">0</span>));</span><br><span class="line">    dim3 <span class="title function_">blocks</span><span class="params">(DIM / <span class="number">16</span>, DIM / <span class="number">16</span>)</span>;</span><br><span class="line">    dim3 <span class="title function_">threads</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span>;</span><br><span class="line">    CPUAnimBitmap *bitmap = d-&gt;bitmap;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//for(int i = 0; i &lt; 90; 0++)&#123;</span></span><br><span class="line">    <span class="comment">//    copy_const_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d-&gt;dev_inSrc, d-&gt;dev_constSrc);</span></span><br><span class="line">    <span class="comment">//    blend_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d-&gt;dev_inSrc, d-&gt;dev_constSrc);</span></span><br><span class="line">    <span class="comment">//    swap(d-&gt;dev_inSrc, d-&gt;dev_outSrc);</span></span><br><span class="line">    <span class="comment">//&#125;</span></span><br><span class="line">    <span class="comment">//float_to_color&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d-&gt;output_bitmap, d-&gt;dev_inSrc);</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//由于tex是全局并且有界的，因此我们必须通过一个标志来选择每次迭代中哪个是输入/输出</span></span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">bool</span> dstOut = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">90</span>; i++)&#123;</span><br><span class="line">        <span class="type">float</span> *in, *out;</span><br><span class="line">        <span class="keyword">if</span>(dstOut)&#123;</span><br><span class="line">            in = d-&gt;dev_inSrc;</span><br><span class="line">            out = d-&gt;dev_outSrc;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            out = d-&gt;dev_inSrc;</span><br><span class="line">            in = d-&gt;dev_outSrc;</span><br><span class="line">        &#125;</span><br><span class="line">        copy_const_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(in);</span><br><span class="line">        blend_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(out, dstOut);</span><br><span class="line">        dstOut = !dstOut;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(bitmap-&gt;get_ptr(), d-&gt;output_bitmap, bitmap-&gt;image_size(), cudaMemcpyDeviceToHost));</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(d-&gt;stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(d-&gt;stop));</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, d-&gt;start, d-&gt;stop));</span><br><span class="line">    </span><br><span class="line">    d-&gt;totalTime += elapsedTime;</span><br><span class="line">    ++d-&gt;frames;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Averaged Time per frame: $3.1f ms \n&quot;</span>, d-&gt;totalTime / d-&gt;frames);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对热传导函数的最后一个修改就是在应用程序运行结束后的清理工作。不仅要释放全局缓冲区，还需要清楚与纹理的绑定：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">anim_exit</span><span class="params">(DataBlock *d)</span>&#123;</span><br><span class="line">    cudaUnbindTexture(textIn);</span><br><span class="line">    cudaUnbindTexture(textOut);</span><br><span class="line">    cudaUnbindTexture(texConstSrc);</span><br><span class="line">    </span><br><span class="line">    cudaFree(d-&gt;dev_inSrc);</span><br><span class="line">    cudaFree(d-&gt;dev_outSrc);</span><br><span class="line">    cudaFree(d-&gt;dev_constSrc);</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(d-&gt;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(d-&gt;stop));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用二维纹理内存"><a href="#使用二维纹理内存" class="headerlink" title="使用二维纹理内存"></a>使用二维纹理内存</h3><p>在多数情况下，二维内存空间是非常有用的。首先，要修改纹理引用的声明。默认的纹理引用都是一维的，因此我们需要增加代表维数的参数2，这表示声明的是一个二维纹理引用。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">texture&lt;<span class="type">float</span>, <span class="number">2</span>&gt; texConstSrc;</span><br><span class="line">textture&lt;<span class="type">float</span>, <span class="number">2</span>&gt; texIn;</span><br><span class="line">textture&lt;<span class="type">float</span>, <span class="number">2</span>&gt; texOut;</span><br></pre></td></tr></table></figure><p>二维纹理将简化blend_kernel()方法的实现。虽然我们需要将tex1Dfeth()调用修改为text2D()调用，但却不再需要通过线性化offset变量以计算top、left、right和bottom等偏移。当使用二维纹理时，可以直接通过x和y来访问纹理。而且当使用tex2D()时，我们不再需要担心发生溢出问题。如果x或y小于0，那么tex2D()将返回0处的值。同理，如果某个值大于宽度，那么tex2D()将返回位于宽度处的值。这些建华带来的好处之一就是核函数的代码将变得更加简单。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">blend_kernel</span><span class="params">(<span class="type">float</span> *dst, <span class="type">bool</span> dstOut)</span>&#123;</span><br><span class="line">    <span class="comment">//将threadIdx/BlockIdx映射到像素位置</span></span><br><span class="line">    <span class="type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> t, l, c, r, b;</span><br><span class="line">    <span class="keyword">if</span>(dstOut)&#123;</span><br><span class="line">        t = text2D(textIn, x, y - <span class="number">1</span>);</span><br><span class="line">        l = text2D(textIn, x - <span class="number">1</span>, y);</span><br><span class="line">        c = text2D(textIn, x, y);</span><br><span class="line">        r = text2D(textIn, x + <span class="number">1</span>, y);</span><br><span class="line">        b = text2D(textIn, x, y + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        t = text2D(textOut, x, y - <span class="number">1</span>);</span><br><span class="line">        l = text2D(textOut, x - <span class="number">1</span>, y);</span><br><span class="line">        c = text2D(textOut, x, y);</span><br><span class="line">        r = text2D(textOut, x + <span class="number">1</span>, y);</span><br><span class="line">        b = text2D(textOut, x, y + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    dst[offset] = c + SPEED * (t + b + r + l - <span class="number">4</span> * c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们也需要对copy_const_kernel()中进行相应的修改。与核函数blend_kernel()类似的是，我们不再需要通过offset来访问纹理，而是只需使用x和y来访问热源的常量。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">copy_const_kernel</span><span class="params">(<span class="type">float</span> *iptr)</span>&#123;</span><br><span class="line">    <span class="comment">//将threadIdx/BlockIdx映射到像素位置</span></span><br><span class="line">    <span class="type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> c = text2D(textConstSrc, x, y);</span><br><span class="line">    <span class="keyword">if</span>(c != <span class="number">0</span>)&#123;</span><br><span class="line">        iptr[offset] = c;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在main()需要对纹理绑定调用进行修改，并告诉运行时：缓冲区将被视为二维纹理而不是一维纹理：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    DataBlock data;</span><br><span class="line">    CPUAnimBitmap <span class="title function_">bitmap</span><span class="params">(DIM, DIM, &amp;data)</span>;</span><br><span class="line">    data.bitmap = &amp;bitmap;</span><br><span class="line">    data.totalTime = <span class="number">0</span>;</span><br><span class="line">    data.frames = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;data.start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;data.stop));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.output_bitmap, bitmap.image_size()));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//假设float类型的大小为4个字符(即rgba)</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_inSrc, bitmap.image_size()));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_outSrc, bitmap.image_size()));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;data.dev_constSrc, bitmap.image_size()));</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    cudaChannelFormatDesc desc = cudaCreateChannelDesc&lt;<span class="type">float</span>&gt;();</span><br><span class="line">    HANDLE_ERROR(cudaBindTexture2D(<span class="literal">NULL</span>, texConstSrc, data.dev_constSrc, desc, DIM, DIM, <span class="keyword">sizeof</span>(<span class="type">float</span> * DIM)));</span><br><span class="line">    HANDLE_ERROR(cudaBindTexture2D(<span class="literal">NULL</span>, texin, data.dev_inSrc, desc, DIM, DIM, <span class="keyword">sizeof</span>(<span class="type">float</span> * DIM)));</span><br><span class="line">    HANDLE_ERROR(cudaBindTexture2D(<span class="literal">NULL</span>, texOut, data.dev_outSrc, desc, DIM, DIM, <span class="keyword">sizeof</span>(<span class="type">float</span> * DIM)));</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *temp = (<span class="type">float</span>*)<span class="built_in">malloc</span>(bitmap.image_size());</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; DIM*DIM; i++)&#123;</span><br><span class="line">        temp[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> x = i % DIM;</span><br><span class="line">        <span class="type">int</span> y =i / DIM;</span><br><span class="line">        <span class="keyword">if</span>((x &gt; <span class="number">300</span>) &amp;&amp; (x &lt; <span class="number">600</span>) &amp;&amp; (y &gt; <span class="number">310</span>) &amp;&amp; (y &lt; <span class="number">601</span>))&#123;</span><br><span class="line">            temp[i] = MAX_TEMP;</span><br><span class="line">        &#125;</span><br><span class="line">        temp[DIM * <span class="number">100</span> + <span class="number">100</span>] = (MAX_TEMP + MIN_TEMP) / <span class="number">2</span>;</span><br><span class="line">        temp[DIM * <span class="number">700</span> + <span class="number">100</span>] = MIN_TEMP;</span><br><span class="line">        temp[DIM * <span class="number">300</span> + <span class="number">300</span>] = MIN_TEMP;</span><br><span class="line">        temp[DIM * <span class="number">200</span> + <span class="number">700</span>] = MIN_TEMP;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> y = <span class="number">800</span>; y &lt; <span class="number">900</span>; y++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> x = <span class="number">400</span>; x &lt; <span class="number">500</span>; x++)&#123;</span><br><span class="line">                temp[x * y * DIM] = MIN_TEMP;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        HANDLE_ERROR(cudaMemcpy(data.dev_constSrc, temp, bitmap.image_size(), cudaMemcpyHostToDevice));</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">free</span>(temp);</span><br><span class="line">        </span><br><span class="line">        bitmap.anim_and_exit((<span class="type">void</span> (*) (<span class="type">void</span>*, <span class="type">int</span>)) anim_gpu, (<span class="type">void</span> (*) (<span class="type">void</span>*)) anim_exit);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然我们需要通过不同的函数来告诉运行时绑定一维纹理还是二维纹理，但是可以通过同一个函数cudaUnbindTexture()来取消纹理绑定。所以执行释放操作的函数anim_exit()可以保持不变。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/02/24/CUDA%E5%AD%A6%E4%B9%A0-%E4%BA%94/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(四)</title>
      <link>http://example.com/2024/02/23/CUDA%E5%AD%A6%E4%B9%A0-%E5%9B%9B/</link>
      <guid>http://example.com/2024/02/23/CUDA%E5%AD%A6%E4%B9%A0-%E5%9B%9B/</guid>
      <pubDate>Fri, 23 Feb 2024 08:43:07 GMT</pubDate>
      
      <description>&lt;p&gt;这一章会介绍如何在CUDA C中使用常量内存、了解常量内存的性能特性以及学习如何使用CUDA事件来测量应用程序的性能。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>这一章会介绍如何在CUDA C中使用常量内存、了解常量内存的性能特性以及学习如何使用CUDA事件来测量应用程序的性能。</p><span id="more"></span><h2 id="常量内存"><a href="#常量内存" class="headerlink" title="常量内存"></a>常量内存</h2><p>到目前为止，我们知道CUDA C程序中可以使用全局内存和共享内存。但是，CUDA C还支持另一种类型的内存，即常量内存。常量内存用于保存在核函数执行期间不会发生变化的数据。在某些情况下，用常量内存来替换全局内存能有效地减少内存带宽。</p><h3 id="在GPU上实现光线跟踪"><a href="#在GPU上实现光线跟踪" class="headerlink" title="在GPU上实现光线跟踪"></a>在GPU上实现光线跟踪</h3><p>我们给出一个简单的光线跟踪应用程序示例来学习。由于OpenGL和DirectX等API都不是专门为了实现光线跟踪而设计的，因此我们必须使用CUDA C来实现基本的光线跟踪器。本示例构造的光线跟踪器非常简单，旨在学习常量内存的使用上(并不能通过示例代码来构建一个功能完备的渲染器)。这个光线跟踪器只支持一组包含球状物体的场景，并且相机被固定在了Z轴，面向原点。此外，示例代码也不支持场景中的任何照明，从而避免二次光线带来的复杂性。代码也不计算照明效果，而只是为每个球面分配一个颜色值，如果它们是可见的，则通过某个预先计算的值对其着色。</p><p>光线跟踪器将从每个像素发射一道光线，并且跟踪到这些光线会命中哪些球面。此外，它还将跟踪每道命中光线的深度。当一道光线穿过多个球面时，只有最接近相机的球面才会被看到。这个代码的光线跟踪器会把相机看不到的球面隐藏起来。</p><p>通过一个数据结构对球面建模，在数据结构中包含了球面的中心坐标(x, y, z)，半径radius，以及颜色值(r, g, b)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> INF 2e10f</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sphere</span>&#123;</span></span><br><span class="line">    <span class="type">float</span> r, g, b;</span><br><span class="line">    <span class="type">float</span> radius;</span><br><span class="line">    <span class="type">float</span> x, y, z;</span><br><span class="line">    __device__ <span class="type">float</span> <span class="title function_">hit</span><span class="params">(<span class="type">float</span> ox, <span class="type">float</span> oy, <span class="type">float</span> *n)</span>&#123;</span><br><span class="line">        <span class="type">float</span> dx = ox - x;</span><br><span class="line">        <span class="type">float</span> dy = oy - y;</span><br><span class="line">        <span class="keyword">if</span>(dx * dx + dy * dy &lt; radius * radius)&#123;</span><br><span class="line">            <span class="type">float</span> dz = sqrtf(radius * radius - dx * dx - dy * dy);</span><br><span class="line">            *n = dz / sqrtf(radius * radius);</span><br><span class="line">            <span class="keyword">return</span> dz + z;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -INF;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个结构中定义了一个方法hit(float ox, float oy, float *n)。对于来自(ox, oy)处像素的光线，这个方法将计算光线是否与这个球面相交。如果光线与球面相交，那么这个方法将计算从相机到光线命中球面处的距离。我们需要这个信息，因为当光线命中多个球面时，只有最接近相机的球面才会被看见。</p><p>main()函数遵循了与前面示例大致相同的代码结构。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cuda.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cpu_bitmap.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> rnd(x) (x * rand() / RAND_MAX)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SPHERES 20</span></span><br><span class="line"></span><br><span class="line">Sphere *s;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">//记录起始时间</span></span><br><span class="line">    cudaEvent_ start, stop;</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;start));</span><br><span class="line">    HANDLE_ERROR(cudaEventCreate(&amp;stop));</span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(start, <span class="number">0</span>));</span><br><span class="line">    </span><br><span class="line">    CPUBitmap <span class="title function_">bitmap</span><span class="params">(DIM, DIM)</span>;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *dev_bitmap;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存以计算输出位图</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_bitmap, bitmap.image_size()));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//为Sphere数据集分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;s, <span class="keyword">sizeof</span>(Sphere) * SPHERES));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在分配输入数据和输出数据的内存后，我们将随机地生成球面的中心坐标，颜色以及半径。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//分配临时内存，对其初始化，并复制到GPU上的内存，然后释放临时内存</span></span><br><span class="line">Sphere *temp_s = (Sphere*) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(Sphere) * SPHERES);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; SPHERES; i++)&#123;</span><br><span class="line">    temp_s[i].r = rnd(<span class="number">1.0f</span>);</span><br><span class="line">    temp_s[i].g = rnd(<span class="number">1.0f</span>);</span><br><span class="line">    temp_s[i].b = rnd(<span class="number">1.0f</span>);</span><br><span class="line">    temp_s[i].x = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">    temp_s[i].y = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">    temp_s[i].z = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">    temp_s[i].radius = rnd(<span class="number">100.0f</span>) + <span class="number">20</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当前，程序将生成一个包含20个球面的随机数组，但这个数量值是通过一个#define宏指定的，因此可以相应的做出调整。</p><p>通过cudaMemcpy()将这个球面数组复制到GPu，然后释放临时缓冲区。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HANDLE_ERROR(cudaMemcpy(s, temps, <span class="keyword">sizeof</span>(Sphere) * SPHERES, cudaMemcpyHostToDevice));</span><br><span class="line"><span class="built_in">free</span>(temp_s);</span><br></pre></td></tr></table></figure><p>现在，输入数据位于GPU上，并且我们已经为输出数据分配好了空间，因此可以启动核函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//从球面数据汇总生成一张位图</span></span><br><span class="line">dim3 <span class="title function_">grids</span><span class="params">(DIM / <span class="number">16</span>, DIM / <span class="number">16</span>)</span>;</span><br><span class="line">dim3 <span class="title function_">threads</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span>;</span><br><span class="line">kernel&lt;&lt;&lt;grids, threads&gt;&gt;&gt;(dev_bitmap);</span><br></pre></td></tr></table></figure><p>这个核函数将执行光线跟踪计算并从输入的一组球面中为每个像素计算颜色数据。最后，我们把输出图像从GPU中复制回来，并显示它。我们还要释放所有已经分配但还未释放的内存。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//将位图从GPU复制回到CPU以显示</span></span><br><span class="line">HANDLE_ERROR(cudaMemcpy(bitmap.get_ptr(), dev_bitmap, bitmap.image_size(), cudaMemcpyDeviceToHost));</span><br><span class="line">bitmap.display_and_exit();</span><br><span class="line"></span><br><span class="line"><span class="comment">//释放内存</span></span><br><span class="line">cudaFree(dev_bitmap);</span><br><span class="line">cudaFree(s);</span><br></pre></td></tr></table></figure><p>下面的代码将介绍如何实现核函数的光线跟踪算法。每个线程都会为输出影像中的一个像素计算颜色值，因此我们遵循一种惯用的方式，计算每个线程对应的x坐标和y坐标，并且根据这两个坐标来计算输出缓冲区的偏移。此外，我们还将把图像坐标(x, y, z)偏移DIM&#x2F;2，这样z轴将穿过图像的中心。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">kernel</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> *ptr)</span>&#123;</span><br><span class="line">    <span class="comment">//将threadIdx/BlockIdx映射到像素位置</span></span><br><span class="line">    <span class="type">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br><span class="line">    <span class="type">float</span> ox = x - DIM / <span class="number">2</span>;</span><br><span class="line">    <span class="type">float</span> oy = y - DIM / <span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//由于每条光线都需要判断与球面相交的情况，因此我们现在对球面数组进行迭代，并判断每个球面的命中情况。</span></span><br><span class="line">    <span class="type">float</span> r = <span class="number">0</span>, g = <span class="number">0</span>, b = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> maxz = -INF;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; SPHERES; i++)&#123;</span><br><span class="line">        <span class="type">float</span> n;</span><br><span class="line">        <span class="type">float</span> t = s[i].hit(ox, oy, &amp;n);</span><br><span class="line">        <span class="keyword">if</span>(t &gt; maxz)&#123;</span><br><span class="line">            <span class="type">float</span> fscale = n;</span><br><span class="line">            r = s[i].r * fscale;</span><br><span class="line">            g = s[i].g * fscale;</span><br><span class="line">            b = s[i].b * fscale;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//在判断了每个球面的相交情况后，可以将当前颜色值保存到输出图像中</span></span><br><span class="line">    ptr[offset * <span class="number">4</span> + <span class="number">0</span>] = (<span class="type">int</span>)(r * <span class="number">255</span>);</span><br><span class="line">    ptr[offset * <span class="number">4</span> + <span class="number">1</span>] = (<span class="type">int</span>)(g * <span class="number">255</span>);</span><br><span class="line">    ptr[offset * <span class="number">4</span> + <span class="number">1</span>] = (<span class="type">int</span>)(b * <span class="number">255</span>);</span><br><span class="line">    ptr[offset * <span class="number">4</span> + <span class="number">3</span>] = <span class="number">255</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="通过常量内存来实现光线跟踪"><a href="#通过常量内存来实现光线跟踪" class="headerlink" title="通过常量内存来实现光线跟踪"></a>通过常量内存来实现光线跟踪</h4><p>上述代码中并没有提到常量内存。下面的代码将使用常量内存来修改这个例子。由于常量内存无法修改，因此显然无法用常量内存来保存输出图像的数据。在这个示例中只有一个输入数据，即球面数组，因此应该将这个数据保存到常量内存中。</p><p>声明数组时，要在前面加上__constant__修饰符。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__constant__ Sphere s[SPHERES];</span><br></pre></td></tr></table></figure><p>最初的示例中，我们声明了一个指针，然后通过cudaMalloc()来为指针分配GPU内存。当我们将其修改为常量内存时，同样要将这个声明修改为在常量内存中静态地分配空间。我们不再需要对球面数组调用cudaMalloc()或cudaFree()。而是在编译时为这个数组提交一个固定的大小。将main()函数修改为常量内存的代码如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    CPUBitmap <span class="title function_">bitmap</span><span class="params">(DIM, DIM)</span>;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *dev_bitmap;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存以计算输出位图</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_bitmap, bitmap.image_size()));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//分配临时内存，对其初始化，并复制到GPU上的内存，然后释放临时内存</span></span><br><span class="line">    Sphere *temp_s = (Sphere*) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(Sphere) * SPHERES);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; SPHERES; i++)&#123;</span><br><span class="line">        temp_s[i].r = rnd(<span class="number">1.0f</span>);</span><br><span class="line">        temp_s[i].g = rnd(<span class="number">1.0f</span>);</span><br><span class="line">        temp_s[i].b = rnd(<span class="number">1.0f</span>);</span><br><span class="line">        temp_s[i].x = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].y = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].z = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].radius = rnd(<span class="number">100.0f</span>) + <span class="number">20</span>;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaMemcpyToSymbol(s, temp_s, <span class="keyword">sizeof</span>(Sphere) * SPHERES));</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">free</span>(temp_s);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//从球面数据中生成一张位图</span></span><br><span class="line">    dim3 <span class="title function_">grids</span><span class="params">(DIM / <span class="number">16</span>, DIM / <span class="number">16</span>)</span>;</span><br><span class="line">    dim3 <span class="title function_">threads</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span>;</span><br><span class="line">    kernel&lt;&lt;&lt;grids, threads&gt;&gt;&gt;(dev_bitmap);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将位图从GPU复制回到CPU以显示</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(bitmap.get_ptr(), dev_bitmap, bitmap.image_size(), cudaMemcpyDeviceToHost));</span><br><span class="line">    bitmap.display_and_exit();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放内存</span></span><br><span class="line">    cudaFree(dev_bitmap);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>cudaMemcpyToSymbol()与参数为cudaMemcpyHostToDevice()的cudaMemcpy()之间唯一差异时cudaMemcpyToSymbol()会复制到常量内存，而cudaMemcpy()会复制到全局内存。</p><h3 id="使用事件来测量性能"><a href="#使用事件来测量性能" class="headerlink" title="使用事件来测量性能"></a>使用事件来测量性能</h3><p>如何判断常量内存对程序性能有着多大影响？最简单的方式就是判断哪个版本的执行事件更短。使用CPU计时器或者操作系统中的某个计时器会带来各种延迟。为了测量GPU在某个任务上话费的时间，我们将使用CUDA的事件API。</p><p>CUDA中的事件本质上是一个GPU时间戳，这个时间戳是在用户指定的时间点上记录的。由于GPU本身支持记录时间戳，因此就避免了当使用CPU定时器来统计GPU执行的事件时可能遇到的诸多问题。比如，下面的代码开头告诉CUDA运行时记录当前的时间，首先创建一个事件，然后记录这个事件。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t start;</span><br><span class="line">cudaEventCreate(&amp;start);</span><br><span class="line">cudaEventRecord(start, <span class="number">0</span>);</span><br></pre></td></tr></table></figure><p>要统计一段代码的执行时间，不仅要创建一个起始事件，还要创建一个结束事件。当在GPU上执行某个工作时，我们不仅要告诉CUDA运行时记录起始时间，还要记录结束时间:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t start, stop;</span><br><span class="line">cudaEventCreate(&amp;start);</span><br><span class="line">cudaEventCreate(&amp;stop);</span><br><span class="line">cudaEventRecord(start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//在GPU执行一些工作</span></span><br><span class="line"></span><br><span class="line">cudaEventRecord(stop, <span class="number">0</span>);</span><br><span class="line">cudaEventSynchronize(stop); <span class="comment">//表示stop事件之前的所有GPU工作已经完成，可以安全读取在stop中保存的时间戳</span></span><br></pre></td></tr></table></figure><p>下面是对光线跟踪器进行性能测试的代码:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//记录起始时间</span></span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">cudaEventCreate(&amp;start);</span><br><span class="line">cudaEventCreate(&amp;stop);</span><br><span class="line">cudaEventRecord(start, <span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    CPUBitmap <span class="title function_">bitmap</span><span class="params">(DIM, DIM)</span>;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *dev_bitmap;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存以计算输出位图</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_bitmap, bitmap.image_size()));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//分配临时内存，对其初始化，并复制到GPU上的内存，然后释放临时内存</span></span><br><span class="line">    Sphere *temp_s = (Sphere*) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(Sphere) * SPHERES);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; SPHERES; i++)&#123;</span><br><span class="line">        temp_s[i].r = rnd(<span class="number">1.0f</span>);</span><br><span class="line">        temp_s[i].g = rnd(<span class="number">1.0f</span>);</span><br><span class="line">        temp_s[i].b = rnd(<span class="number">1.0f</span>);</span><br><span class="line">        temp_s[i].x = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].y = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].z = rnd(<span class="number">1000.0f</span>) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].radius = rnd(<span class="number">100.0f</span>) + <span class="number">20</span>;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaMemcpyToSymbol(s, temp_s, <span class="keyword">sizeof</span>(Sphere) * SPHERES));</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">free</span>(temp_s);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//从球面数据中生成一张位图</span></span><br><span class="line">    dim3 <span class="title function_">grids</span><span class="params">(DIM / <span class="number">16</span>, DIM / <span class="number">16</span>)</span>;</span><br><span class="line">    dim3 <span class="title function_">threads</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span>;</span><br><span class="line">    kernel&lt;&lt;&lt;grids, threads&gt;&gt;&gt;(dev_bitmap);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将位图从GPU复制回到CPU以显示</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(bitmap.get_ptr(), dev_bitmap, bitmap.image_size(), cudaMemcpyDeviceToHost));</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">//获得结束时间，并显示计时结果</span></span><br><span class="line">    HANDLE_ERROR(cudaEventRecord(stop, <span class="number">0</span>));</span><br><span class="line">    HANDLE_ERROR(cudaEventSynchronize(stop));</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> elapsedTime;</span><br><span class="line">    HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time to generate: %3.1f ms\n&quot;</span>, elapsedTime);</span><br><span class="line">    </span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(start));</span><br><span class="line">    HANDLE_ERROR(cudaEventDestroy(stop));    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">//显示位图</span></span><br><span class="line">    bitmap.display_and_exit();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放内存</span></span><br><span class="line">    cudaFree(dev_bitmap);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/02/23/CUDA%E5%AD%A6%E4%B9%A0-%E5%9B%9B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(三)</title>
      <link>http://example.com/2024/02/21/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%89/</link>
      <guid>http://example.com/2024/02/21/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%89/</guid>
      <pubDate>Wed, 21 Feb 2024 11:03:11 GMT</pubDate>
      
      <description>&lt;p&gt;这一章将介绍线程块以及线程之间的通信机制和同步机制。&lt;/p&gt;
&lt;p&gt;在GPU启动并行代码的实现方法是告诉CUDA运行时启动核函数的多个并行副本。我们将这些并行副本称为线程块(Block)。&lt;/p&gt;
&lt;p&gt;CUDA运行时将把这些线程块分解为多个线程。当需要启动多个并行线程块时，只需将尖括号中的第一个参数由1改为想要启动的线程块数量。&lt;/p&gt;
&lt;p&gt;在尖括号中，第二个参数表示CUDA运行时在每个线程块中创建的线程数量。假设尖括号中的变量为&amp;lt;&amp;lt;&amp;lt;N, M&amp;gt;&amp;gt;&amp;gt;总共启动的线程数量可以按照以下公式计算:&lt;br&gt;$$&lt;br&gt;N个线程块 * M个线程&amp;#x2F;线程块 &amp;#x3D; N*M个并行线程&lt;br&gt;$$&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>这一章将介绍线程块以及线程之间的通信机制和同步机制。</p><p>在GPU启动并行代码的实现方法是告诉CUDA运行时启动核函数的多个并行副本。我们将这些并行副本称为线程块(Block)。</p><p>CUDA运行时将把这些线程块分解为多个线程。当需要启动多个并行线程块时，只需将尖括号中的第一个参数由1改为想要启动的线程块数量。</p><p>在尖括号中，第二个参数表示CUDA运行时在每个线程块中创建的线程数量。假设尖括号中的变量为&lt;&lt;&lt;N, M&gt;&gt;&gt;总共启动的线程数量可以按照以下公式计算:<br>$$<br>N个线程块 * M个线程&#x2F;线程块 &#x3D; N*M个并行线程<br>$$</p><span id="more"></span><h3 id="使用线程实现GPU上的矢量求和"><a href="#使用线程实现GPU上的矢量求和" class="headerlink" title="使用线程实现GPU上的矢量求和"></a>使用线程实现GPU上的矢量求和</h3><p>在之前的代码中，我们才去的时调用N个线程块，每个线程块对应一个线程<code>add&lt;&lt;&lt;N, 1&gt;&gt;&gt;(dev_a, dev_b, dev_c);</code>。</p><p>如果我们启动N个线程，并且所有线程都在一个线程块中，则可以表示为<code>add&lt;&lt;&lt;1, N&gt;&gt;&gt;(dev_a, dev_b, dev_c);</code>。此外，因为只有一个线程块，我们需要通过线程索引来对数据进行索引(而不是线程块索引)，需要将<code>int tid = blockIdx.x;</code>修改为<code>int tid = threadIdx.x;</code></p><h3 id="在GPU上对更长的矢量求和"><a href="#在GPU上对更长的矢量求和" class="headerlink" title="在GPU上对更长的矢量求和"></a>在GPU上对更长的矢量求和</h3><p>对于启动核函数时每个线程块中的线程数量，硬件也进行了限制。具体来说，最大的线程数量不能超过设备树形结构中maxThreadsPerBlock域的值。对目前的GPU来说一个线程块最多有1024个线程。如果要通过并行线程对长度大于1024的矢量进行相加的话，就需要将线程与线程块结合起来才能实现。</p><p>此时，计算索引可以表示为:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br></pre></td></tr></table></figure><p>blockDim保存的事线程块中每一维的线程数量，由于使用的事一维线程块，因此只用到blockDim.x。</p><p>此外，gridDim是二维的，而blockDim是三维的。</p><p>假如我们使用多个线程块处理N个并行线程，每个线程块处理的线程数量为128，那样可以启动N&#x2F;128个线程块。然而问题在于，当N小于128时，比如127，那么N&#x2F;128等于0，此时将会启动0个线程块。所以我们希望这个除法能够向上取整。我们可以不用调用 ceil()函数，而是将计算改为(N+127)&#x2F;N。因此，这个例子调用核函数可以写为:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add&lt;&lt;&lt;(N + <span class="number">127</span>) / <span class="number">128</span>, <span class="number">128</span>&gt;&gt;&gt;(dev_a, dev_b, dev_c);</span><br></pre></td></tr></table></figure><p>当N不是128的整数倍时，将启动过多的线程。然而，在核函数中已经解决了这个问题。在访问输入数组和输出数组之前，必须检查线程的便宜是否位于0到N之间。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(tid &lt; N)&#123;</span><br><span class="line">c[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此，当索引越过数组的边界时，核函数将自动停止执行计算。核函数不会对越过数组边界的内存进行读取或者写入。</p><h3 id="在GPU上对任意长度的矢量求和"><a href="#在GPU上对任意长度的矢量求和" class="headerlink" title="在GPU上对任意长度的矢量求和"></a>在GPU上对任意长度的矢量求和</h3><p>当矢量的长度很长时，我们可以让每一个线程执行多个矢量相加。例如</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">while</span>(tid &lt; N)&#123;</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">        tid += blockDim.x * gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当每个线程计算完当前索引上的任务后，接着就需要对索引进行递增，其中递增的步长为线程格中正在运行的线程数量。这个数值等于每个线程块中的线程数量乘上线程格中线程块的数量，即blockDim.x * gridDim.x。</p><h3 id="共享内存和同步"><a href="#共享内存和同步" class="headerlink" title="共享内存和同步"></a>共享内存和同步</h3><p>CUDA C编译器对共享内存中的变量与普通变量分别采取不同的处理方式。对于在GPU上启动的每个线程块，CUDA C编译器都将创建该变量的一个副本，线程块中的每个线程都共享这块内存，但线程却无法看到也不能修改其他线程块的变量副本。这就实现了一个非常好的方式，<strong>使得一个线程块中的多个线程能够在计算上进行通信和协作</strong>。</p><p>而且，共享内存缓冲区驻留在物理GPU上，而不是驻留在GPU之外的系统内存中。因此，<strong>在访问共享内存时的延迟要远远低于访问普通缓冲区的延迟</strong>，使得共享内存像每个线程块的高速缓存或者中间结果暂存器那样高效。</p><p>如果想要实现线程之间通信，那么还需要一种机制来实现线程之间的同步。例如，如果线程A将一个值写入到共享内存，并且我们希望线程B对这个值进行一些操作，那么只有当线程A的写入操作完成之后，线程B才能开始执行它的操作。如果没有同步，那么将发生竞态条件(race condition)。</p><p>下面将通过一个矢量的点积运算来详细介绍共享内存和同步。矢量点积运算为矢量相乘结束后将值相加起来以得到一个标量输出值。例如对两个包含4个元素的矢量进行点积运算:<br>$$<br>(x_1, x_2, x_3, x_4) * (y_1, y_2, y_3, y_4) &#x3D; x_1y_1 + x_2y_2 + x_3y_3 + x_4y_4<br>$$<br>由于最终结果是所有乘积的总和，因此每个线程要保存它所计算的乘积的加和。下面代码实现了点积函数的第一个步骤:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> imin(a, b) (a &lt; b ? a : b)</span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">33</span> * <span class="number">1024</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">dot</span><span class="params">(<span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">float</span> *c)</span>&#123;</span><br><span class="line">    __shared__ <span class="type">float</span> cache[threadsPerBlock];</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> cacheIndex = threadIdx.x;</span><br><span class="line">    <span class="type">float</span> temp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(tid &lt; N)&#123;</span><br><span class="line">        temp += a[tid] * b[tid];</span><br><span class="line">        tid += blockDim.x * gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//设置cache中相应位置上的值</span></span><br><span class="line">    cache[cacheIndex] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码中声明了一个共享内存缓冲区，名字为cache。这个缓冲区将保存每个线程计算的加和值。我们将cache数组的大小声明为threadsPerBlock，这样线程块中每个线程都能将它计算的临时结果保存到某个位置上。之前在分配全局内存时，我们为每个执行核函数的线程都分配了足够的内存，即线程块的数量乘以threadsPerBlock。但对于共享变量来说，由于编译器将为每个线程块生成共享变量的一个副本，因此只需根据线程块中线程的数量来分配内存。</p><p>我们需要将cache中所有的值相加起来。在执行这个运算时，需要通过一个线程来读取保存在cache中的值。由于race condition，我们需要使用下面的代码来确保对所有共享数组cache[]的写入操作在读组cache之前完成:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//对线程块中的线程进行同步</span></span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure><p>这个函数调用将确保线程块中的每个线程都执行完__syncthreads()前面的语句后，才会执行下一条语句。</p><p>这时，我们可以将其中的值相加起来(称为归约Reduction)。代码的基本思想是每个线程将cache[]中的两个值相加起来，然后将结果保存回cache[]。由于每个线程都将两个值合并为一个值，那么在完成这个步骤后，得到的结果数量就是计算开始时数值数量的一半。下一个步骤中我们对这一半数值执行相同的操作，在将这种操作执行log2(threadsPerBlock)步骤后，就能得到cache[]中所有值的总和。对于这个示例来说，我们在每个线程块中使用了256个线程，因此需要8次迭代将cache[]中的256个值归约为1个值。这个归约过程的实现可以表示为以下代码:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//对于归约运算来说，以下代码要求threadsPerBlock必须时2的指数</span></span><br><span class="line"><span class="type">int</span> i = blockDim.x / <span class="number">2</span>;</span><br><span class="line"><span class="keyword">while</span>(i != <span class="number">0</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span>(cacheIndex &lt; i)&#123;</span><br><span class="line">        cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    i /= <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再结束了while()循环后，每个线程块都得到了一个值，这个值位于cache[]的第一个元素中，并且就等于该线程块中两两元素乘积的加和。然后，我们将这个值保存到全局内存并结束核函数:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(cacheIndex == <span class="number">0</span>)&#123;</span><br><span class="line">    c[blockIdx.x] = cache[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只让cacheIndex为0的线程执行保存操作时因为每个线程块只有一个值写入到全局内存，因此每个线程块只需要一个线程来执行这个操作。最后，由于每个线程块都只写入一个值到全局数据c[]中，因此可以通过blockIdx来索引这个值。</p><p>点积运算的最后一个步骤就是计算c[]中所有元素的总和。像GPU这种大规模的并行机器在执行最后的归约步骤时，通常会浪费计算资源，因为此时的数据集往往会非常小。因此，我们可以将执行控制返回给主机，并且由CPU来完成最后一个加法步骤。</p><p>下面给出了完整的代码实现:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> imin(a, b) (a &lt; b? a : b)</span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">33</span> * <span class="number">1024</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> blocksPerGrid = imin(<span class="number">32</span>, (N + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock);</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">dot</span><span class="params">(<span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">float</span> *c)</span>&#123;</span><br><span class="line">    __shared__ <span class="type">float</span> cache[threadsPerBlock];</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> cacheIndex = threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> temp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(tid &lt; N)&#123;</span><br><span class="line">        temp += a[tid] * b[tid];</span><br><span class="line">        tid += blockDim.x * gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//设置cache中相应位置上的值</span></span><br><span class="line">    cache[cacheIndex] = temp;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//对线程块中的线程进行同步</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//对于归约来说，以下代码要求threadsPerBlock必须是2的指数</span></span><br><span class="line">    <span class="type">int</span> i = blockDim.x / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span>(i != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(cacheIndex &lt; i)&#123;</span><br><span class="line">            cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads(); <span class="comment">//循环中更新了变量cache，所以需要在下一次循环前进行同步。该同步语句需要所有的线程都必须运行才行。如果有线程不能运行这一处代码，会导致其他线程永远等待。</span></span><br><span class="line">        i /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(cacheIndex == <span class="number">0</span>)&#123;</span><br><span class="line">        c[blockIndex.x] = cache[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">float</span> *a, *b, c, *partial_c;</span><br><span class="line">    <span class="type">float</span> *dev_c, *dev_b, *dev_partial_c;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在CPU上分配内存</span></span><br><span class="line">    a = (<span class="type">float</span>*) <span class="built_in">malloc</span>(N*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    b = (<span class="type">float</span>*) <span class="built_in">malloc</span>(N*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    partial_c = (<span class="type">float</span>*) <span class="built_in">malloc</span>(blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a, N * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_b, N * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//填充主机内存</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = i * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将数组&quot;a&quot;和&quot;b&quot;复制到GPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_a, a, N * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_b, b, N * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_partial_c);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将数组&quot;c&quot;从GPU复制到CPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDeviceToHost));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在CPU上完成最终的求和运算</span></span><br><span class="line">    c = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; blocksPerGrid; i++)&#123;</span><br><span class="line">        c += partial_c[i];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">#<span class="keyword">define</span> sum_squares(x) (x * (x + 1) * (2 * x + 1) / 6)</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Does GPU value %.6g = %.6g? \n&quot;</span>, c, <span class="number">2</span> * sum_square((<span class="type">float</span>) (N - <span class="number">1</span>)));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//释放GPU上的内存</span></span><br><span class="line">    cudaFree(dev_a);</span><br><span class="line">    cudaFree(dev_b);</span><br><span class="line">    cudaFree(dev_partial_c);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//释放CPU上的内存</span></span><br><span class="line">    <span class="built_in">free</span>(a);</span><br><span class="line">    <span class="built_in">free</span>(b);</span><br><span class="line">    <span class="built_in">free</span>(partial_c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/02/21/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%89/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(二)</title>
      <link>http://example.com/2024/02/21/CUDA%E5%AD%A6%E4%B9%A0-%E4%BA%8C/</link>
      <guid>http://example.com/2024/02/21/CUDA%E5%AD%A6%E4%B9%A0-%E4%BA%8C/</guid>
      <pubDate>Wed, 21 Feb 2024 06:27:12 GMT</pubDate>
      
      <description>&lt;p&gt;这一部分将介绍CUDA的并行编程方式&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>这一部分将介绍CUDA的并行编程方式</p><span id="more"></span><h2 id="矢量求和运算"><a href="#矢量求和运算" class="headerlink" title="矢量求和运算"></a>矢量求和运算</h2><p>假设有两组数据，我们需要将这两组数据中对应的元素两两相加，并将结果保存在第三个数组中。</p><h3 id="基于CPU的矢量求和"><a href="#基于CPU的矢量求和" class="headerlink" title="基于CPU的矢量求和"></a>基于CPU的矢量求和</h3><p>首先，下面的代码是通过传统的C代码来实现这个求和运算</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 10</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span>&#123;</span><br><span class="line"><span class="type">int</span> tid = <span class="number">0</span>;<span class="comment">//这是第0个CPU，因此索引从0开始</span></span><br><span class="line">    <span class="keyword">while</span>(tid &lt; N)&#123;</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">        tid += <span class="number">1</span>;<span class="comment">//由于只有一个CPU，因此每次递增1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> a[N], b[N], c[N];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在CPU上为数组&quot;a&quot;和&quot;b&quot;赋值</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        a[i] = -i;</span><br><span class="line">        b[i] = i * i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    add(a, b, c);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//显示结果</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d + %d = %d\n&quot;</span>, a[i], b[i], c[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>add()中使用while循环而不是for循环是为了代码能够在拥有多个CPU或者多个CPU核的系统上并行运行，比如双核处理器上可以将每次递增的大小改为2。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//第一个CPU核</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(tid &lt; N)&#123;</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">        tid += <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//第二个CPU核</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(tid &lt; N)&#123;</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">        tid += <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="基于GPU的矢量求和"><a href="#基于GPU的矢量求和" class="headerlink" title="基于GPU的矢量求和"></a>基于GPU的矢量求和</h3><p>下面是基于GPU的矢量求和代码</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 10</span></span><br><span class="line"></span><br><span class="line">__global__ <span class="title function_">add</span><span class="params">(<span class="type">int</span> *dev_a, <span class="type">int</span> *dev_c, <span class="type">int</span> *dev_c)</span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x; <span class="comment">//计算该索引处的数据</span></span><br><span class="line">    <span class="keyword">if</span>(tid &lt; N)&#123;</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> a[N], b[N], c[N];</span><br><span class="line">    <span class="type">int</span> *dev_a, *dev_b, *dev_c;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在GPU上分配内存</span></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_a, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_b, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_c, N * <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在CPU上为数组&quot;a&quot;和&quot;b&quot;赋值</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        a[i] = -i;</span><br><span class="line">        b[i] = i * i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将数组&quot;a&quot;和&quot;b&quot;复制到GPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_a, a, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(dev_b, b, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice));</span><br><span class="line">    </span><br><span class="line">    add&lt;&lt;&lt;N, <span class="number">1</span>&gt;&gt;&gt;(dev_a, dev_b, dev_c);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//将数组&quot;c&quot;从GPU复制到CPU</span></span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(c, dev_c, N * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//显示结果</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d + %d = %d\n&quot;</span>, a[i], b[i], c[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//释放在GPU上分配的内存</span></span><br><span class="line">    cudaFree(dev_a);</span><br><span class="line">    cudaFree(dev_b);</span><br><span class="line">    cudaFree(dev_c);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在示例代码中，调用add函数的尖括号内的数值是&lt;&lt;&lt;N, 1&gt;&gt;&gt;，其中第一个参数表示设备在执行核函数时使用的并行线程块的数量。比如如果制定的事kernel&lt;&lt;&lt;256, 1&gt;&gt;&gt;()，那么将有256个线程块在GPU上运行。</p><p>在add函数里面，我们可以使用blockIdx.x获取具体的线程块(blockIdx是一个内置变量，不需要定义它)，通过这种方式可以让不同的线程块并行执行数组的矢量相加。</p><p>下一章将会详细解释线程块以及线程之间的通信机制和同步机制。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/02/21/CUDA%E5%AD%A6%E4%B9%A0-%E4%BA%8C/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CUDA学习(一)</title>
      <link>http://example.com/2024/02/20/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%80/</link>
      <guid>http://example.com/2024/02/20/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%80/</guid>
      <pubDate>Tue, 20 Feb 2024 09:50:03 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;strong&gt;参考书目:&lt;/strong&gt; GPU高性能编程CUDA实战&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;书目网页链接:&lt;/strong&gt; &lt;a href=&quot;https://hpc.pku.edu.cn/docs/20170829223652566150.pdf&quot;&gt;https://hpc.pku.edu.cn/docs/20170829223652566150.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;该博客参考于上述书籍，虽然书有一点老，但是作为初学者而言仍然能学到很多东西。&lt;/p&gt;
&lt;p&gt;本书所包含的代码都在下面的连接中，可以下载来学习: &lt;a href=&quot;https://developer.nvidia.com/cuda-example&quot;&gt;https://developer.nvidia.com/cuda-example&lt;/a&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><strong>参考书目:</strong> GPU高性能编程CUDA实战</p><p><strong>书目网页链接:</strong> <a href="https://hpc.pku.edu.cn/docs/20170829223652566150.pdf">https://hpc.pku.edu.cn/docs/20170829223652566150.pdf</a></p><p>该博客参考于上述书籍，虽然书有一点老，但是作为初学者而言仍然能学到很多东西。</p><p>本书所包含的代码都在下面的连接中，可以下载来学习: <a href="https://developer.nvidia.com/cuda-example">https://developer.nvidia.com/cuda-example</a></p><span id="more"></span><h2 id="CUDA-C简介"><a href="#CUDA-C简介" class="headerlink" title="CUDA C简介"></a>CUDA C简介</h2><p>首先来看一个CUDA C的示例:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">  prinf(<span class="string">&quot;Hello World!\n&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个示例只是为了说明，CUDA C与熟悉的标准C在很大程度上是没有区别的。</p><h3 id="核函数调用"><a href="#核函数调用" class="headerlink" title="核函数调用"></a>核函数调用</h3><p>在GPU设备上执行的函数通常称为核函数(Kernel)</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">kernel</span><span class="params">()</span>&#123;</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">  kernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Hello World!\n&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>跟之前的代码相比多了两处</p><ul><li>一个空的函数kernel()，并且带有修饰符__global__。</li><li>对这个空函数的调用，并且带有修饰字符&lt;&lt;&lt;1, 1&gt;&gt;&gt;。</li></ul><p>这个__global__可以认为是告诉编译器，函数应该编译为在设备而不是在主机上运行。函数kernel()将被交给编译器设备代码的编译器，而main()函数将被交给主机编译器。</p><h3 id="传递参数"><a href="#传递参数" class="headerlink" title="传递参数"></a>传递参数</h3><p>以下是对上述代码的进一步修改，可以实现将参数传递给核函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;book.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span>* c)</span>&#123;</span><br><span class="line">    *c = a + b;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;c is %d\n&quot;</span>, *c);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="type">int</span> c = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span>* dev_c;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;original c is %d\n&quot;</span>, c);</span><br><span class="line"></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_c, <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    add&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(<span class="number">2</span>, <span class="number">7</span>, dev_c);</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(&amp;c, dev_c, <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost));</span><br><span class="line"></span><br><span class="line">    cudaFree(dev_c);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2 + 7 = %d\n&quot;</span>, c);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中”book.h”包含了HANDLE_ERROR，也可以不使用”book.h”而是在代码中添加HANDLE_ERROR函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">HandleError</span><span class="params">( cudaError_t err,</span></span><br><span class="line"><span class="params">                         <span class="type">const</span> <span class="type">char</span> *file,</span></span><br><span class="line"><span class="params">                         <span class="type">int</span> line )</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (err != cudaSuccess) &#123;</span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">&quot;%s in %s at line %d\n&quot;</span>, cudaGetErrorString( err ),</span><br><span class="line">                file, line );</span><br><span class="line">        <span class="built_in">exit</span>( EXIT_FAILURE );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))</span></span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span>* c)</span>&#123;</span><br><span class="line">    *c = a + b;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;c is %d\n&quot;</span>, *c);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="type">int</span> c = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span>* dev_c;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;original c is %d\n&quot;</span>, c);</span><br><span class="line"></span><br><span class="line">    HANDLE_ERROR(cudaMalloc((<span class="type">void</span>**)&amp;dev_c, <span class="keyword">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    add&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(<span class="number">2</span>, <span class="number">7</span>, dev_c);</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(&amp;c, dev_c, <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;2 + 7 = %d\n&quot;</span>, c);</span><br><span class="line">    cudaFree(dev_c);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>cudaMalloc()用来分配内存，这个函数的调用行为非常类似于标准C函数的malloc()，但该函数作用是告诉CUDA运行时在设备上分配内存。<ul><li>第一个参数是一个指针，指向用于保存新分配内存地址的变量。第二个参数是分配内存的大小。</li><li>该函数返回的类型是void*。</li><li>不能使用标准C的free()函数来释放cudaMallocc()分配的内存。要释放cudaMalloc()分配的内存，需要调用cudaFree()。</li></ul></li><li>HANDLE_ERROR()是定义的一个宏，作为辅助代码的一部分，用来判断函数调用是否返回了一个错误值，如果是的话，将输出相应的错误消息。</li><li>在主机代码中可以通过调用cudaMemcpy()来访问设备上的内存。<ul><li>第一个参数是目标(target)指针，第二个参数是源(source)指针，第三个参数分配内存大小。第四个参数则是指定设备内存指针。</li><li>第四个参数一般有cudaMemcpyDeviceToHost，cudaMemcpyHostToDevice, cudaMemcpyDeviceToDevice三种。cudaMemcpyDeviceToHost说明我们将设备内存指针的数据传递给主机内存指针，此时第一个参数指针是在主机上，第二个参数指针是在设备上。cudaMemcpyHostToDevice说明我们将主机内存指针的数据传递给设备内存指针，此时第一个参数指针是在设备上，第二个参数指针是在主机上。此外还可以通过传递参数cudaMemcpyDeviceToDevice莱高速运行时这两个指针都在设备上。如果源指针和目标指针都在主机上，则可以直接调用memcpy()函数。</li></ul></li></ul><h3 id="查询设备"><a href="#查询设备" class="headerlink" title="查询设备"></a>查询设备</h3><p>我们可以使用cudaGetDeviceCount()来查询设备数量(比如GPU数量)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> count;</span><br><span class="line">HANDLE_ERROR(cudaGetDeviceCount(&amp;count));</span><br></pre></td></tr></table></figure><p>CUDA设备属性包含很多信息，可以在书上或者NVIDIA官方网站上查到。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/CUDA/">CUDA</category>
      
      
      
      <comments>http://example.com/2024/02/20/CUDA%E5%AD%A6%E4%B9%A0-%E4%B8%80/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
